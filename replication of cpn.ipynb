{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from keras.layers import BatchNormalization, Lambda, Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category= FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mycolournet():\n",
    "    input_image = Input(shape=(56,56,3))\n",
    "    layer1 = MaxPooling2D(pool_size=(1,1),strides=(1,1),input_shape=(56,56,3))(input_image)\n",
    "    \n",
    "    blueinput =  Lambda(lambda x : x[:,:,:,0:1])(layer1)\n",
    "    greeninput =  Lambda(lambda x : x[:,:,:,1:2])(layer1)\n",
    "    redinput =  Lambda(lambda x : x[:,:,:,:2])(layer1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    blueconv1 = Convolution2D(filters=16,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(blueinput)\n",
    "    blueconv1 = BatchNormalization()(blueconv1)\n",
    "    blueconv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(blueconv1)\n",
    "    \n",
    "    greenconv1 = Convolution2D(filters=16,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(greeninput)\n",
    "    greenconv1 = BatchNormalization()(greenconv1)\n",
    "    greenconv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(greenconv1)\n",
    "    \n",
    "    redconv1 = Convolution2D(filters=16,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(redinput)\n",
    "    redconv1 = BatchNormalization()(redconv1)\n",
    "    redconv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(redconv1)\n",
    "    \n",
    "    blueconv2 = Convolution2D(filters=32,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(blueconv1)\n",
    "    blueconv2 = BatchNormalization()(blueconv2)\n",
    "    blueconv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(blueconv2)\n",
    "    \n",
    "    greenconv2 = Convolution2D(filters=32,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(greenconv1)\n",
    "    greenconv2 = BatchNormalization()(greenconv2)\n",
    "    greenconv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(greenconv2)\n",
    "    \n",
    "    redconv2 = Convolution2D(filters=32,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(redconv1)\n",
    "    redconv2 = BatchNormalization()(redconv2)\n",
    "    redconv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(redconv2)\n",
    "    \n",
    "    blueflatten = Flatten()(blueconv2)\n",
    "    greenflatten = Flatten()(greenconv2)\n",
    "    redflatten = Flatten()(redconv2)\n",
    "    \n",
    "    blueFC_1 = Dense(units=200, activation='relu')(blueflatten)\n",
    "    blueFC_1 = Dropout(0.6)(blueFC_1)\n",
    "    blueFC_2 = Dense(units=1, activation='relu')(blueFC_1)\n",
    "    \n",
    "    greenFC_1 = Dense(units=200, activation='relu')(greenflatten)\n",
    "    greenFC_1 = Dropout(0.6)(greenFC_1)\n",
    "    greenFC_2 = Dense(units=1, activation='relu')(greenFC_1)\n",
    "    \n",
    "    redFC_1 = Dense(units=200, activation='relu')(redflatten)\n",
    "    redFC_1 = Dropout(0.6)(redFC_1)\n",
    "    redFC_2 = Dense(units=1, activation='relu')(redFC_1)\n",
    "    \n",
    "    concatoutput = Concatenate()([blueFC_2, greenFC_2,redFC_2])\n",
    "    \n",
    "    cpn1 = Dense(units = 100, activation = 'relu')(concatoutput)\n",
    "    cpn1=  Dense(units = 20 , activation = 'relu')(cpn1)\n",
    "    cpn1=  Dense(units = 2 , activation = 'relu')(cpn1)\n",
    "    \n",
    "    cpn2_1 = Dense(units = 40, activation = 'relu')(cpn1)\n",
    "    cpn2_1 = Dense(units = 100, activation = 'relu')(cpn2_1)\n",
    "    cpn2_1 = Dense(units = 4, activation = 'relu')(cpn2_1)  #red, yellow,orange,pink\n",
    "    \n",
    "    \n",
    "    \n",
    "    cpn2_2 = Dense(units = 40, activation = 'relu')(cpn1)\n",
    "    cpn2_2 = Dense(units = 100, activation = 'relu')(cpn2_2)\n",
    "    cpn2_2 = Dense(units = 3, activation = 'relu')(cpn2_2)  #blue, purple, green\n",
    "    \n",
    "    finalconcat =Concatenate()([cpn2_1, cpn2_2])\n",
    "    output= Activation(activation = 'softmax')(finalconcat)\n",
    "    \n",
    "    model = Model(inputs=input_image,outputs=output)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # sgd = SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mycolournet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/colors/train'\n",
    "valid_path = 'data/colors/valid'\n",
    "test_path = 'data/colors/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1054 images belonging to 7 classes.\n",
      "Found 72 images belonging to 7 classes.\n",
      "Found 2 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['red','yellow','orange', 'pink', 'blue', 'purple','green'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['red','yellow','orange', 'pink', 'blue', 'purple','green' ], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['red','yellow','orange', 'pink', 'blue', 'purple','green' ], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 27s - loss: 1.9444 - accuracy: 0.1779 - val_loss: 1.9524 - val_accuracy: 0.0833\n",
      "Epoch 2/200\n",
      "94/94 - 11s - loss: 1.9364 - accuracy: 0.2133 - val_loss: 1.9582 - val_accuracy: 0.1111\n",
      "Epoch 3/200\n",
      "94/94 - 11s - loss: 1.8961 - accuracy: 0.2744 - val_loss: 2.0039 - val_accuracy: 0.0833\n",
      "Epoch 4/200\n",
      "94/94 - 10s - loss: 1.7996 - accuracy: 0.3033 - val_loss: 1.8715 - val_accuracy: 0.1528\n",
      "Epoch 5/200\n",
      "94/94 - 11s - loss: 1.7675 - accuracy: 0.3205 - val_loss: 1.9049 - val_accuracy: 0.1528\n",
      "Epoch 6/200\n",
      "94/94 - 11s - loss: 1.7359 - accuracy: 0.3355 - val_loss: 1.9172 - val_accuracy: 0.1667\n",
      "Epoch 7/200\n",
      "94/94 - 12s - loss: 1.7233 - accuracy: 0.3258 - val_loss: 2.0056 - val_accuracy: 0.1528\n",
      "Epoch 8/200\n",
      "94/94 - 11s - loss: 1.7237 - accuracy: 0.3333 - val_loss: 1.9364 - val_accuracy: 0.1667\n",
      "Epoch 9/200\n",
      "94/94 - 12s - loss: 1.6975 - accuracy: 0.3398 - val_loss: 1.8554 - val_accuracy: 0.1667\n",
      "Epoch 10/200\n",
      "94/94 - 14s - loss: 1.6920 - accuracy: 0.3355 - val_loss: 1.9451 - val_accuracy: 0.1667\n",
      "Epoch 11/200\n",
      "94/94 - 14s - loss: 1.6865 - accuracy: 0.3408 - val_loss: 1.9280 - val_accuracy: 0.1667\n",
      "Epoch 12/200\n",
      "94/94 - 13s - loss: 1.6749 - accuracy: 0.3430 - val_loss: 2.0101 - val_accuracy: 0.1667\n",
      "Epoch 13/200\n",
      "94/94 - 12s - loss: 1.6639 - accuracy: 0.3516 - val_loss: 1.9586 - val_accuracy: 0.1528\n",
      "Epoch 14/200\n",
      "94/94 - 11s - loss: 1.6610 - accuracy: 0.3473 - val_loss: 1.9446 - val_accuracy: 0.1528\n",
      "Epoch 15/200\n",
      "94/94 - 12s - loss: 1.6542 - accuracy: 0.3430 - val_loss: 1.9191 - val_accuracy: 0.1528\n",
      "Epoch 16/200\n",
      "94/94 - 14s - loss: 1.6555 - accuracy: 0.3451 - val_loss: 1.9338 - val_accuracy: 0.1667\n",
      "Epoch 17/200\n",
      "94/94 - 13s - loss: 1.6262 - accuracy: 0.3558 - val_loss: 1.7710 - val_accuracy: 0.1528\n",
      "Epoch 18/200\n",
      "94/94 - 12s - loss: 1.5968 - accuracy: 0.3516 - val_loss: 1.7826 - val_accuracy: 0.1528\n",
      "Epoch 19/200\n",
      "94/94 - 12s - loss: 1.5760 - accuracy: 0.3537 - val_loss: 1.7680 - val_accuracy: 0.1667\n",
      "Epoch 20/200\n",
      "94/94 - 13s - loss: 1.5743 - accuracy: 0.3537 - val_loss: 1.7720 - val_accuracy: 0.1528\n",
      "Epoch 21/200\n",
      "94/94 - 12s - loss: 1.5622 - accuracy: 0.3558 - val_loss: 1.7857 - val_accuracy: 0.1667\n",
      "Epoch 22/200\n",
      "94/94 - 12s - loss: 1.5809 - accuracy: 0.3591 - val_loss: 1.7600 - val_accuracy: 0.1667\n",
      "Epoch 23/200\n",
      "94/94 - 12s - loss: 1.5581 - accuracy: 0.3601 - val_loss: 1.7282 - val_accuracy: 0.1528\n",
      "Epoch 24/200\n",
      "94/94 - 12s - loss: 1.5613 - accuracy: 0.3494 - val_loss: 1.7527 - val_accuracy: 0.1667\n",
      "Epoch 25/200\n",
      "94/94 - 12s - loss: 1.5418 - accuracy: 0.3644 - val_loss: 1.7356 - val_accuracy: 0.1528\n",
      "Epoch 26/200\n",
      "94/94 - 12s - loss: 1.5408 - accuracy: 0.3580 - val_loss: 1.7751 - val_accuracy: 0.1389\n",
      "Epoch 27/200\n",
      "94/94 - 12s - loss: 1.5324 - accuracy: 0.3655 - val_loss: 1.7841 - val_accuracy: 0.1667\n",
      "Epoch 28/200\n",
      "94/94 - 12s - loss: 1.5349 - accuracy: 0.3719 - val_loss: 1.7841 - val_accuracy: 0.1389\n",
      "Epoch 29/200\n",
      "94/94 - 12s - loss: 1.5215 - accuracy: 0.3730 - val_loss: 1.7951 - val_accuracy: 0.1528\n",
      "Epoch 30/200\n",
      "94/94 - 12s - loss: 1.5007 - accuracy: 0.3773 - val_loss: 1.7533 - val_accuracy: 0.1806\n",
      "Epoch 31/200\n",
      "94/94 - 12s - loss: 1.5158 - accuracy: 0.3773 - val_loss: 1.8098 - val_accuracy: 0.1806\n",
      "Epoch 32/200\n",
      "94/94 - 12s - loss: 1.5060 - accuracy: 0.3901 - val_loss: 1.8971 - val_accuracy: 0.1667\n",
      "Epoch 33/200\n",
      "94/94 - 12s - loss: 1.5108 - accuracy: 0.3762 - val_loss: 1.7167 - val_accuracy: 0.1667\n",
      "Epoch 34/200\n",
      "94/94 - 12s - loss: 1.4841 - accuracy: 0.4544 - val_loss: 1.7798 - val_accuracy: 0.3333\n",
      "Epoch 35/200\n",
      "94/94 - 12s - loss: 1.4871 - accuracy: 0.5456 - val_loss: 1.7068 - val_accuracy: 0.3333\n",
      "Epoch 36/200\n",
      "94/94 - 12s - loss: 1.4672 - accuracy: 0.5466 - val_loss: 1.6864 - val_accuracy: 0.3333\n",
      "Epoch 37/200\n",
      "94/94 - 12s - loss: 1.4704 - accuracy: 0.5531 - val_loss: 1.8080 - val_accuracy: 0.3472\n",
      "Epoch 38/200\n",
      "94/94 - 12s - loss: 1.4846 - accuracy: 0.5413 - val_loss: 1.7376 - val_accuracy: 0.3472\n",
      "Epoch 39/200\n",
      "94/94 - 13s - loss: 1.4233 - accuracy: 0.5520 - val_loss: 1.6532 - val_accuracy: 0.3611\n",
      "Epoch 40/200\n",
      "94/94 - 12s - loss: 1.4032 - accuracy: 0.5584 - val_loss: 1.6837 - val_accuracy: 0.3750\n",
      "Epoch 41/200\n",
      "94/94 - 12s - loss: 1.3766 - accuracy: 0.5681 - val_loss: 1.6524 - val_accuracy: 0.3750\n",
      "Epoch 42/200\n",
      "94/94 - 12s - loss: 1.3477 - accuracy: 0.5584 - val_loss: 1.8188 - val_accuracy: 0.3750\n",
      "Epoch 43/200\n",
      "94/94 - 12s - loss: 1.3188 - accuracy: 0.5713 - val_loss: 1.6870 - val_accuracy: 0.3611\n",
      "Epoch 44/200\n",
      "94/94 - 12s - loss: 1.2790 - accuracy: 0.5723 - val_loss: 1.6951 - val_accuracy: 0.3611\n",
      "Epoch 45/200\n",
      "94/94 - 12s - loss: 1.2539 - accuracy: 0.5798 - val_loss: 1.7962 - val_accuracy: 0.3333\n",
      "Epoch 46/200\n",
      "94/94 - 13s - loss: 1.2277 - accuracy: 0.5723 - val_loss: 1.7404 - val_accuracy: 0.3333\n",
      "Epoch 47/200\n",
      "94/94 - 12s - loss: 1.2145 - accuracy: 0.5798 - val_loss: 1.6168 - val_accuracy: 0.3889\n",
      "Epoch 48/200\n",
      "94/94 - 12s - loss: 1.1831 - accuracy: 0.5788 - val_loss: 1.5763 - val_accuracy: 0.3472\n",
      "Epoch 49/200\n",
      "94/94 - 12s - loss: 1.2065 - accuracy: 0.5756 - val_loss: 1.5016 - val_accuracy: 0.3472\n",
      "Epoch 50/200\n",
      "94/94 - 12s - loss: 1.1556 - accuracy: 0.5884 - val_loss: 1.5672 - val_accuracy: 0.4028\n",
      "Epoch 51/200\n",
      "94/94 - 12s - loss: 1.1233 - accuracy: 0.5970 - val_loss: 1.5018 - val_accuracy: 0.4028\n",
      "Epoch 52/200\n",
      "94/94 - 13s - loss: 1.0943 - accuracy: 0.6206 - val_loss: 1.5400 - val_accuracy: 0.3611\n",
      "Epoch 53/200\n",
      "94/94 - 12s - loss: 1.0849 - accuracy: 0.6345 - val_loss: 1.5438 - val_accuracy: 0.4306\n",
      "Epoch 54/200\n",
      "94/94 - 13s - loss: 1.0762 - accuracy: 0.6420 - val_loss: 1.4931 - val_accuracy: 0.3889\n",
      "Epoch 55/200\n",
      "94/94 - 12s - loss: 1.1304 - accuracy: 0.6227 - val_loss: 1.5246 - val_accuracy: 0.4167\n",
      "Epoch 56/200\n",
      "94/94 - 13s - loss: 1.0760 - accuracy: 0.6527 - val_loss: 1.5705 - val_accuracy: 0.4306\n",
      "Epoch 57/200\n",
      "94/94 - 13s - loss: 1.0363 - accuracy: 0.6667 - val_loss: 1.3833 - val_accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "94/94 - 12s - loss: 1.0108 - accuracy: 0.6913 - val_loss: 1.4118 - val_accuracy: 0.4722\n",
      "Epoch 59/200\n",
      "94/94 - 12s - loss: 1.0017 - accuracy: 0.6731 - val_loss: 1.4448 - val_accuracy: 0.4167\n",
      "Epoch 60/200\n",
      "94/94 - 13s - loss: 1.0248 - accuracy: 0.6838 - val_loss: 1.6279 - val_accuracy: 0.4306\n",
      "Epoch 61/200\n",
      "94/94 - 12s - loss: 0.9822 - accuracy: 0.6913 - val_loss: 1.6437 - val_accuracy: 0.4306\n",
      "Epoch 62/200\n",
      "94/94 - 12s - loss: 0.9737 - accuracy: 0.6902 - val_loss: 1.4796 - val_accuracy: 0.5139\n",
      "Epoch 63/200\n",
      "94/94 - 13s - loss: 0.9973 - accuracy: 0.6913 - val_loss: 1.3847 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "94/94 - 13s - loss: 0.9555 - accuracy: 0.7053 - val_loss: 1.4204 - val_accuracy: 0.5139\n",
      "Epoch 65/200\n",
      "94/94 - 12s - loss: 0.9178 - accuracy: 0.7192 - val_loss: 1.4130 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "94/94 - 13s - loss: 0.8996 - accuracy: 0.7256 - val_loss: 1.4598 - val_accuracy: 0.5278\n",
      "Epoch 67/200\n",
      "94/94 - 12s - loss: 0.9133 - accuracy: 0.7342 - val_loss: 1.3505 - val_accuracy: 0.5694\n",
      "Epoch 68/200\n",
      "94/94 - 13s - loss: 0.9392 - accuracy: 0.7106 - val_loss: 1.5629 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "94/94 - 13s - loss: 0.8809 - accuracy: 0.7267 - val_loss: 1.6205 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "94/94 - 12s - loss: 0.9007 - accuracy: 0.7299 - val_loss: 1.5712 - val_accuracy: 0.4722\n",
      "Epoch 71/200\n",
      "94/94 - 12s - loss: 0.8591 - accuracy: 0.7428 - val_loss: 1.2987 - val_accuracy: 0.5139\n",
      "Epoch 72/200\n",
      "94/94 - 12s - loss: 0.8565 - accuracy: 0.7471 - val_loss: 1.3675 - val_accuracy: 0.5417\n",
      "Epoch 73/200\n",
      "94/94 - 13s - loss: 0.8534 - accuracy: 0.7428 - val_loss: 1.5272 - val_accuracy: 0.5694\n",
      "Epoch 74/200\n",
      "94/94 - 13s - loss: 0.8071 - accuracy: 0.7663 - val_loss: 1.5325 - val_accuracy: 0.5556\n",
      "Epoch 75/200\n",
      "94/94 - 13s - loss: 0.8604 - accuracy: 0.7374 - val_loss: 1.2799 - val_accuracy: 0.6250\n",
      "Epoch 76/200\n",
      "94/94 - 13s - loss: 0.8104 - accuracy: 0.7599 - val_loss: 1.7258 - val_accuracy: 0.5139\n",
      "Epoch 77/200\n",
      "94/94 - 14s - loss: 0.7975 - accuracy: 0.7653 - val_loss: 1.3774 - val_accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "94/94 - 14s - loss: 0.7737 - accuracy: 0.7631 - val_loss: 1.4653 - val_accuracy: 0.5556\n",
      "Epoch 79/200\n",
      "94/94 - 13s - loss: 0.9564 - accuracy: 0.7117 - val_loss: 1.4356 - val_accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "94/94 - 13s - loss: 0.9450 - accuracy: 0.7095 - val_loss: 1.4068 - val_accuracy: 0.5139\n",
      "Epoch 81/200\n",
      "94/94 - 14s - loss: 0.8098 - accuracy: 0.7578 - val_loss: 1.4168 - val_accuracy: 0.5139\n",
      "Epoch 82/200\n",
      "94/94 - 17s - loss: 0.8126 - accuracy: 0.7417 - val_loss: 1.5093 - val_accuracy: 0.5278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "94/94 - 15s - loss: 0.7687 - accuracy: 0.7749 - val_loss: 1.4885 - val_accuracy: 0.5833\n",
      "Epoch 84/200\n",
      "94/94 - 13s - loss: 0.7513 - accuracy: 0.7878 - val_loss: 1.7060 - val_accuracy: 0.4861\n",
      "Epoch 85/200\n",
      "94/94 - 14s - loss: 0.7707 - accuracy: 0.7728 - val_loss: 1.5997 - val_accuracy: 0.5694\n",
      "Epoch 86/200\n",
      "94/94 - 13s - loss: 0.7464 - accuracy: 0.7749 - val_loss: 1.5545 - val_accuracy: 0.5556\n",
      "Epoch 87/200\n",
      "94/94 - 13s - loss: 0.8291 - accuracy: 0.7471 - val_loss: 1.5079 - val_accuracy: 0.5278\n",
      "Epoch 88/200\n",
      "94/94 - 13s - loss: 0.7684 - accuracy: 0.7717 - val_loss: 1.5788 - val_accuracy: 0.5278\n",
      "Epoch 89/200\n",
      "94/94 - 15s - loss: 0.8098 - accuracy: 0.7685 - val_loss: 1.5170 - val_accuracy: 0.5833\n",
      "Epoch 90/200\n",
      "94/94 - 13s - loss: 0.7326 - accuracy: 0.7889 - val_loss: 1.7493 - val_accuracy: 0.4861\n",
      "Epoch 91/200\n",
      "94/94 - 13s - loss: 0.7702 - accuracy: 0.7760 - val_loss: 1.5590 - val_accuracy: 0.5278\n",
      "Epoch 92/200\n",
      "94/94 - 13s - loss: 0.7244 - accuracy: 0.7835 - val_loss: 1.5570 - val_accuracy: 0.5694\n",
      "Epoch 93/200\n",
      "94/94 - 13s - loss: 0.6805 - accuracy: 0.8039 - val_loss: 1.7118 - val_accuracy: 0.4861\n",
      "Epoch 94/200\n",
      "94/94 - 13s - loss: 0.7129 - accuracy: 0.7974 - val_loss: 1.5431 - val_accuracy: 0.5417\n",
      "Epoch 95/200\n",
      "94/94 - 13s - loss: 0.6980 - accuracy: 0.7921 - val_loss: 1.9017 - val_accuracy: 0.4861\n",
      "Epoch 96/200\n",
      "94/94 - 13s - loss: 0.6684 - accuracy: 0.8092 - val_loss: 2.0187 - val_accuracy: 0.4722\n",
      "Epoch 97/200\n",
      "94/94 - 13s - loss: 0.6597 - accuracy: 0.8135 - val_loss: 1.6313 - val_accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "94/94 - 13s - loss: 0.6925 - accuracy: 0.7985 - val_loss: 1.8783 - val_accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "94/94 - 13s - loss: 0.6595 - accuracy: 0.7964 - val_loss: 1.8199 - val_accuracy: 0.5278\n",
      "Epoch 100/200\n",
      "94/94 - 14s - loss: 0.6616 - accuracy: 0.7964 - val_loss: 1.6459 - val_accuracy: 0.5000\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6b70592e1423>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     verbose=2)    \n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=200,\n",
    "    verbose=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 - 14s - loss: 1.9446 - accuracy: 0.1784 - val_loss: 1.9437 - val_accuracy: 0.1667\n",
      "Epoch 2/200\n",
      "106/106 - 14s - loss: 1.9421 - accuracy: 0.1812 - val_loss: 1.9421 - val_accuracy: 0.1667\n",
      "Epoch 3/200\n",
      "106/106 - 14s - loss: 1.9409 - accuracy: 0.1812 - val_loss: 1.9399 - val_accuracy: 0.1667\n",
      "Epoch 4/200\n",
      "106/106 - 14s - loss: 1.9391 - accuracy: 0.1812 - val_loss: 1.9390 - val_accuracy: 0.1667\n",
      "Epoch 5/200\n",
      "106/106 - 15s - loss: 1.9371 - accuracy: 0.1812 - val_loss: 1.9368 - val_accuracy: 0.1667\n",
      "Epoch 6/200\n",
      "106/106 - 14s - loss: 1.9295 - accuracy: 0.1812 - val_loss: 1.9310 - val_accuracy: 0.1667\n",
      "Epoch 7/200\n",
      "106/106 - 14s - loss: 1.9163 - accuracy: 0.1812 - val_loss: 1.9107 - val_accuracy: 0.1667\n",
      "Epoch 8/200\n",
      "106/106 - 14s - loss: 1.8709 - accuracy: 0.2685 - val_loss: 1.8271 - val_accuracy: 0.2778\n",
      "Epoch 9/200\n",
      "106/106 - 14s - loss: 1.7830 - accuracy: 0.3340 - val_loss: 1.7688 - val_accuracy: 0.2639\n",
      "Epoch 10/200\n",
      "106/106 - 14s - loss: 1.7159 - accuracy: 0.3643 - val_loss: 1.6591 - val_accuracy: 0.2917\n",
      "Epoch 11/200\n",
      "106/106 - 14s - loss: 1.6184 - accuracy: 0.3416 - val_loss: 1.5830 - val_accuracy: 0.2778\n",
      "Epoch 12/200\n",
      "106/106 - 14s - loss: 1.5534 - accuracy: 0.3435 - val_loss: 1.5654 - val_accuracy: 0.2361\n",
      "Epoch 13/200\n",
      "106/106 - 14s - loss: 1.5281 - accuracy: 0.3586 - val_loss: 1.5699 - val_accuracy: 0.2500\n",
      "Epoch 14/200\n",
      "106/106 - 14s - loss: 1.4840 - accuracy: 0.3529 - val_loss: 1.5038 - val_accuracy: 0.3056\n",
      "Epoch 15/200\n",
      "106/106 - 14s - loss: 1.4773 - accuracy: 0.3548 - val_loss: 1.4884 - val_accuracy: 0.2639\n",
      "Epoch 16/200\n",
      "106/106 - 14s - loss: 1.4456 - accuracy: 0.3653 - val_loss: 1.4945 - val_accuracy: 0.3056\n",
      "Epoch 17/200\n",
      "106/106 - 14s - loss: 1.4523 - accuracy: 0.3520 - val_loss: 1.5085 - val_accuracy: 0.3056\n",
      "Epoch 18/200\n",
      "106/106 - 14s - loss: 1.4398 - accuracy: 0.3700 - val_loss: 1.5085 - val_accuracy: 0.3194\n",
      "Epoch 19/200\n",
      "106/106 - 14s - loss: 1.4226 - accuracy: 0.3947 - val_loss: 1.4892 - val_accuracy: 0.3194\n",
      "Epoch 20/200\n",
      "106/106 - 14s - loss: 1.3962 - accuracy: 0.3880 - val_loss: 1.4799 - val_accuracy: 0.3056\n",
      "Epoch 21/200\n",
      "106/106 - 14s - loss: 1.3966 - accuracy: 0.3947 - val_loss: 1.5088 - val_accuracy: 0.3194\n",
      "Epoch 22/200\n",
      "106/106 - 14s - loss: 1.3865 - accuracy: 0.3975 - val_loss: 1.4716 - val_accuracy: 0.3194\n",
      "Epoch 23/200\n",
      "106/106 - 14s - loss: 1.3682 - accuracy: 0.4061 - val_loss: 1.4874 - val_accuracy: 0.2778\n",
      "Epoch 24/200\n",
      "106/106 - 14s - loss: 1.3518 - accuracy: 0.3956 - val_loss: 1.4486 - val_accuracy: 0.2917\n",
      "Epoch 25/200\n",
      "106/106 - 14s - loss: 1.3410 - accuracy: 0.4165 - val_loss: 1.4619 - val_accuracy: 0.3194\n",
      "Epoch 26/200\n",
      "106/106 - 14s - loss: 1.3089 - accuracy: 0.4326 - val_loss: 1.4578 - val_accuracy: 0.3056\n",
      "Epoch 27/200\n",
      "106/106 - 14s - loss: 1.3239 - accuracy: 0.4213 - val_loss: 1.4835 - val_accuracy: 0.3611\n",
      "Epoch 28/200\n",
      "106/106 - 14s - loss: 1.3587 - accuracy: 0.4137 - val_loss: 1.4839 - val_accuracy: 0.3611\n",
      "Epoch 29/200\n",
      "106/106 - 14s - loss: 1.2929 - accuracy: 0.4241 - val_loss: 1.4697 - val_accuracy: 0.3056\n",
      "Epoch 30/200\n",
      "106/106 - 14s - loss: 1.3091 - accuracy: 0.4355 - val_loss: 1.4519 - val_accuracy: 0.3611\n",
      "Epoch 31/200\n",
      "106/106 - 14s - loss: 1.2913 - accuracy: 0.4459 - val_loss: 1.4718 - val_accuracy: 0.3194\n",
      "Epoch 32/200\n",
      "106/106 - 14s - loss: 1.2889 - accuracy: 0.4535 - val_loss: 1.4616 - val_accuracy: 0.3611\n",
      "Epoch 33/200\n",
      "106/106 - 15s - loss: 1.2602 - accuracy: 0.4611 - val_loss: 1.4429 - val_accuracy: 0.3611\n",
      "Epoch 34/200\n",
      "106/106 - 14s - loss: 1.3003 - accuracy: 0.4345 - val_loss: 1.4970 - val_accuracy: 0.3333\n",
      "Epoch 35/200\n",
      "106/106 - 14s - loss: 1.2893 - accuracy: 0.4288 - val_loss: 1.4284 - val_accuracy: 0.3333\n",
      "Epoch 36/200\n",
      "106/106 - 14s - loss: 1.2493 - accuracy: 0.4583 - val_loss: 1.4980 - val_accuracy: 0.3472\n",
      "Epoch 37/200\n",
      "106/106 - 14s - loss: 1.2552 - accuracy: 0.4592 - val_loss: 1.4640 - val_accuracy: 0.3472\n",
      "Epoch 38/200\n",
      "106/106 - 14s - loss: 1.2765 - accuracy: 0.4459 - val_loss: 1.4245 - val_accuracy: 0.3333\n",
      "Epoch 39/200\n",
      "106/106 - 14s - loss: 1.2401 - accuracy: 0.4459 - val_loss: 1.4345 - val_accuracy: 0.3472\n",
      "Epoch 40/200\n",
      "106/106 - 14s - loss: 1.2569 - accuracy: 0.4677 - val_loss: 1.5329 - val_accuracy: 0.2778\n",
      "Epoch 41/200\n",
      "106/106 - 14s - loss: 1.2161 - accuracy: 0.4791 - val_loss: 1.4629 - val_accuracy: 0.3194\n",
      "Epoch 42/200\n",
      "106/106 - 14s - loss: 1.2180 - accuracy: 0.5009 - val_loss: 1.5016 - val_accuracy: 0.3333\n",
      "Epoch 43/200\n",
      "106/106 - 14s - loss: 1.2365 - accuracy: 0.4877 - val_loss: 1.4123 - val_accuracy: 0.3611\n",
      "Epoch 44/200\n",
      "106/106 - 15s - loss: 1.1890 - accuracy: 0.4905 - val_loss: 1.4806 - val_accuracy: 0.3472\n",
      "Epoch 45/200\n",
      "106/106 - 14s - loss: 1.1784 - accuracy: 0.4886 - val_loss: 1.4785 - val_accuracy: 0.3611\n",
      "Epoch 46/200\n",
      "106/106 - 14s - loss: 1.3608 - accuracy: 0.4402 - val_loss: 1.5176 - val_accuracy: 0.2917\n",
      "Epoch 47/200\n",
      "106/106 - 14s - loss: 1.2530 - accuracy: 0.4858 - val_loss: 1.4898 - val_accuracy: 0.3194\n",
      "Epoch 48/200\n",
      "106/106 - 14s - loss: 1.2442 - accuracy: 0.4839 - val_loss: 1.5354 - val_accuracy: 0.3056\n",
      "Epoch 49/200\n",
      "106/106 - 14s - loss: 1.2817 - accuracy: 0.4734 - val_loss: 1.4539 - val_accuracy: 0.3750\n",
      "Epoch 50/200\n",
      "106/106 - 14s - loss: 1.1937 - accuracy: 0.5142 - val_loss: 1.4769 - val_accuracy: 0.3056\n",
      "Epoch 51/200\n",
      "106/106 - 14s - loss: 1.1437 - accuracy: 0.5294 - val_loss: 1.4884 - val_accuracy: 0.3333\n",
      "Epoch 52/200\n",
      "106/106 - 14s - loss: 1.1704 - accuracy: 0.5161 - val_loss: 1.4578 - val_accuracy: 0.3472\n",
      "Epoch 53/200\n",
      "106/106 - 14s - loss: 1.1719 - accuracy: 0.5199 - val_loss: 1.4434 - val_accuracy: 0.3472\n",
      "Epoch 54/200\n",
      "106/106 - 15s - loss: 1.0886 - accuracy: 0.5408 - val_loss: 1.4827 - val_accuracy: 0.3611\n",
      "Epoch 55/200\n",
      "106/106 - 14s - loss: 1.0873 - accuracy: 0.5408 - val_loss: 1.6068 - val_accuracy: 0.3472\n",
      "Epoch 56/200\n",
      "106/106 - 14s - loss: 1.1982 - accuracy: 0.5218 - val_loss: 1.6341 - val_accuracy: 0.3056\n",
      "Epoch 57/200\n",
      "106/106 - 14s - loss: 1.2500 - accuracy: 0.4991 - val_loss: 1.5779 - val_accuracy: 0.3056\n",
      "Epoch 58/200\n",
      "106/106 - 14s - loss: 1.1234 - accuracy: 0.5218 - val_loss: 1.6116 - val_accuracy: 0.3056\n",
      "Epoch 59/200\n",
      "106/106 - 14s - loss: 1.2035 - accuracy: 0.5095 - val_loss: 1.6426 - val_accuracy: 0.2917\n",
      "Epoch 60/200\n",
      "106/106 - 14s - loss: 1.1533 - accuracy: 0.5275 - val_loss: 1.6270 - val_accuracy: 0.3333\n",
      "Epoch 61/200\n",
      "106/106 - 14s - loss: 1.2212 - accuracy: 0.5190 - val_loss: 1.5427 - val_accuracy: 0.3056\n",
      "Epoch 62/200\n",
      "106/106 - 14s - loss: 1.1107 - accuracy: 0.5313 - val_loss: 1.6421 - val_accuracy: 0.2778\n",
      "Epoch 63/200\n",
      "106/106 - 14s - loss: 1.1690 - accuracy: 0.5123 - val_loss: 1.5231 - val_accuracy: 0.3611\n",
      "Epoch 64/200\n",
      "106/106 - 14s - loss: 1.0978 - accuracy: 0.5512 - val_loss: 1.5849 - val_accuracy: 0.3194\n",
      "Epoch 65/200\n",
      "106/106 - 14s - loss: 1.1150 - accuracy: 0.5389 - val_loss: 1.6148 - val_accuracy: 0.3472\n",
      "Epoch 66/200\n",
      "106/106 - 15s - loss: 1.1046 - accuracy: 0.5474 - val_loss: 1.5445 - val_accuracy: 0.3611\n",
      "Epoch 67/200\n",
      "106/106 - 15s - loss: 1.1326 - accuracy: 0.5351 - val_loss: 1.4705 - val_accuracy: 0.3472\n",
      "Epoch 68/200\n",
      "106/106 - 14s - loss: 1.1249 - accuracy: 0.5408 - val_loss: 1.5879 - val_accuracy: 0.3472\n",
      "Epoch 69/200\n",
      "106/106 - 14s - loss: 1.1369 - accuracy: 0.5398 - val_loss: 1.6991 - val_accuracy: 0.3472\n",
      "Epoch 70/200\n",
      "106/106 - 14s - loss: 1.1023 - accuracy: 0.5579 - val_loss: 1.6910 - val_accuracy: 0.3333\n",
      "Epoch 71/200\n",
      "106/106 - 14s - loss: 1.1301 - accuracy: 0.5522 - val_loss: 1.6579 - val_accuracy: 0.3056\n",
      "Epoch 72/200\n",
      "106/106 - 14s - loss: 1.0911 - accuracy: 0.5626 - val_loss: 1.6293 - val_accuracy: 0.3611\n",
      "Epoch 73/200\n",
      "106/106 - 14s - loss: 1.0524 - accuracy: 0.5664 - val_loss: 1.7768 - val_accuracy: 0.2917\n",
      "Epoch 74/200\n",
      "106/106 - 14s - loss: 1.0632 - accuracy: 0.5683 - val_loss: 1.7664 - val_accuracy: 0.3194\n",
      "Epoch 75/200\n",
      "106/106 - 14s - loss: 1.1617 - accuracy: 0.5275 - val_loss: 1.8285 - val_accuracy: 0.2222\n",
      "Epoch 76/200\n",
      "106/106 - 14s - loss: 1.0933 - accuracy: 0.5655 - val_loss: 1.5820 - val_accuracy: 0.3472\n",
      "Epoch 77/200\n",
      "106/106 - 14s - loss: 1.0912 - accuracy: 0.5655 - val_loss: 1.6619 - val_accuracy: 0.3194\n",
      "Epoch 78/200\n",
      "106/106 - 14s - loss: 1.4580 - accuracy: 0.4611 - val_loss: 1.9825 - val_accuracy: 0.2361\n",
      "Epoch 79/200\n",
      "106/106 - 14s - loss: 1.6242 - accuracy: 0.3786 - val_loss: 1.9360 - val_accuracy: 0.2361\n",
      "Epoch 80/200\n",
      "106/106 - 14s - loss: 1.4281 - accuracy: 0.4336 - val_loss: 1.8142 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "106/106 - 14s - loss: 1.1738 - accuracy: 0.5237 - val_loss: 1.5804 - val_accuracy: 0.2917\n",
      "Epoch 82/200\n",
      "106/106 - 14s - loss: 1.1624 - accuracy: 0.5512 - val_loss: 1.5423 - val_accuracy: 0.3611\n",
      "Epoch 83/200\n",
      "106/106 - 14s - loss: 1.1308 - accuracy: 0.5408 - val_loss: 1.5429 - val_accuracy: 0.3333\n",
      "Epoch 84/200\n",
      "106/106 - 14s - loss: 1.0583 - accuracy: 0.5712 - val_loss: 1.6587 - val_accuracy: 0.3472\n",
      "Epoch 85/200\n",
      "106/106 - 14s - loss: 1.0401 - accuracy: 0.5797 - val_loss: 1.7382 - val_accuracy: 0.3194\n",
      "Epoch 86/200\n",
      "106/106 - 14s - loss: 1.1104 - accuracy: 0.5427 - val_loss: 1.6807 - val_accuracy: 0.3333\n",
      "Epoch 87/200\n",
      "106/106 - 14s - loss: 1.0519 - accuracy: 0.5778 - val_loss: 1.6161 - val_accuracy: 0.3194\n",
      "Epoch 88/200\n",
      "106/106 - 14s - loss: 1.0583 - accuracy: 0.5797 - val_loss: 1.7662 - val_accuracy: 0.2778\n",
      "Epoch 89/200\n",
      "106/106 - 14s - loss: 1.0492 - accuracy: 0.5702 - val_loss: 1.7363 - val_accuracy: 0.2639\n",
      "Epoch 90/200\n",
      "106/106 - 14s - loss: 1.1699 - accuracy: 0.5389 - val_loss: 1.7790 - val_accuracy: 0.2778\n",
      "Epoch 91/200\n",
      "106/106 - 14s - loss: 1.1623 - accuracy: 0.5455 - val_loss: 2.0431 - val_accuracy: 0.2083\n",
      "Epoch 92/200\n",
      "106/106 - 14s - loss: 1.4483 - accuracy: 0.4469 - val_loss: 1.8872 - val_accuracy: 0.2500\n",
      "Epoch 93/200\n",
      "106/106 - 14s - loss: 1.4341 - accuracy: 0.4431 - val_loss: 1.9747 - val_accuracy: 0.2778\n",
      "Epoch 94/200\n",
      "106/106 - 14s - loss: 1.4165 - accuracy: 0.4478 - val_loss: 1.8458 - val_accuracy: 0.2500\n",
      "Epoch 95/200\n",
      "106/106 - 14s - loss: 1.5909 - accuracy: 0.3710 - val_loss: 1.8735 - val_accuracy: 0.2500\n",
      "Epoch 96/200\n",
      "106/106 - 14s - loss: 1.3249 - accuracy: 0.4772 - val_loss: 1.8714 - val_accuracy: 0.2500\n",
      "Epoch 97/200\n",
      "106/106 - 14s - loss: 1.2251 - accuracy: 0.5000 - val_loss: 2.0412 - val_accuracy: 0.2778\n",
      "Epoch 98/200\n",
      "106/106 - 14s - loss: 1.2379 - accuracy: 0.4972 - val_loss: 2.0266 - val_accuracy: 0.2639\n",
      "Epoch 99/200\n",
      "106/106 - 14s - loss: 1.1797 - accuracy: 0.5323 - val_loss: 2.0499 - val_accuracy: 0.2917\n",
      "Epoch 100/200\n",
      "106/106 - 14s - loss: 1.2390 - accuracy: 0.5133 - val_loss: 1.8060 - val_accuracy: 0.2500\n",
      "Epoch 101/200\n",
      "106/106 - 14s - loss: 1.2149 - accuracy: 0.5152 - val_loss: 1.8311 - val_accuracy: 0.2917\n",
      "Epoch 102/200\n",
      "106/106 - 14s - loss: 1.1721 - accuracy: 0.5275 - val_loss: 1.8947 - val_accuracy: 0.2361\n",
      "Epoch 103/200\n",
      "106/106 - 14s - loss: 1.1309 - accuracy: 0.5474 - val_loss: 2.0607 - val_accuracy: 0.2917\n",
      "Epoch 104/200\n",
      "106/106 - 14s - loss: 1.0904 - accuracy: 0.5569 - val_loss: 2.0022 - val_accuracy: 0.2917\n",
      "Epoch 105/200\n",
      "106/106 - 14s - loss: 1.1228 - accuracy: 0.5389 - val_loss: 1.8912 - val_accuracy: 0.3333\n",
      "Epoch 106/200\n",
      "106/106 - 14s - loss: 1.0859 - accuracy: 0.5645 - val_loss: 1.8790 - val_accuracy: 0.3194\n",
      "Epoch 107/200\n",
      "106/106 - 14s - loss: 1.2844 - accuracy: 0.4791 - val_loss: 1.9664 - val_accuracy: 0.2083\n",
      "Epoch 108/200\n",
      "106/106 - 15s - loss: 1.5818 - accuracy: 0.3937 - val_loss: 1.8138 - val_accuracy: 0.2778\n",
      "Epoch 109/200\n",
      "106/106 - 15s - loss: 1.3001 - accuracy: 0.5123 - val_loss: 1.8014 - val_accuracy: 0.2778\n",
      "Epoch 110/200\n",
      "106/106 - 14s - loss: 1.2914 - accuracy: 0.5323 - val_loss: 1.8804 - val_accuracy: 0.2361\n",
      "Epoch 111/200\n",
      "106/106 - 14s - loss: 1.3669 - accuracy: 0.4658 - val_loss: 1.9625 - val_accuracy: 0.2222\n",
      "Epoch 112/200\n",
      "106/106 - 14s - loss: 1.3397 - accuracy: 0.4763 - val_loss: 1.9333 - val_accuracy: 0.2778\n",
      "Epoch 113/200\n",
      "106/106 - 14s - loss: 1.2775 - accuracy: 0.4953 - val_loss: 2.0355 - val_accuracy: 0.2639\n",
      "Epoch 114/200\n",
      "106/106 - 14s - loss: 1.1534 - accuracy: 0.5380 - val_loss: 1.7987 - val_accuracy: 0.2917\n",
      "Epoch 115/200\n",
      "106/106 - 14s - loss: 1.1193 - accuracy: 0.5569 - val_loss: 1.8298 - val_accuracy: 0.3333\n",
      "Epoch 116/200\n",
      "106/106 - 14s - loss: 1.1681 - accuracy: 0.5256 - val_loss: 1.8541 - val_accuracy: 0.3056\n",
      "Epoch 117/200\n",
      "106/106 - 14s - loss: 1.1986 - accuracy: 0.5266 - val_loss: 1.8036 - val_accuracy: 0.3056\n",
      "Epoch 118/200\n",
      "106/106 - 14s - loss: 1.1399 - accuracy: 0.5370 - val_loss: 1.9087 - val_accuracy: 0.3194\n",
      "Epoch 119/200\n",
      "106/106 - 14s - loss: 1.1308 - accuracy: 0.5417 - val_loss: 1.6986 - val_accuracy: 0.3333\n",
      "Epoch 120/200\n",
      "106/106 - 14s - loss: 1.1577 - accuracy: 0.5351 - val_loss: 1.9498 - val_accuracy: 0.2778\n",
      "Epoch 121/200\n",
      "106/106 - 14s - loss: 1.2335 - accuracy: 0.5066 - val_loss: 2.0511 - val_accuracy: 0.2639\n",
      "Epoch 122/200\n",
      "106/106 - 14s - loss: 1.1910 - accuracy: 0.5256 - val_loss: 1.8664 - val_accuracy: 0.3333\n",
      "Epoch 123/200\n",
      "106/106 - 14s - loss: 1.1233 - accuracy: 0.5484 - val_loss: 1.9482 - val_accuracy: 0.3333\n",
      "Epoch 124/200\n",
      "106/106 - 14s - loss: 1.1124 - accuracy: 0.5323 - val_loss: 1.8607 - val_accuracy: 0.3056\n",
      "Epoch 125/200\n",
      "106/106 - 14s - loss: 1.1354 - accuracy: 0.5446 - val_loss: 1.8375 - val_accuracy: 0.3333\n",
      "Epoch 126/200\n",
      "106/106 - 14s - loss: 1.1043 - accuracy: 0.5455 - val_loss: 1.7654 - val_accuracy: 0.3333\n",
      "Epoch 127/200\n",
      "106/106 - 14s - loss: 1.3185 - accuracy: 0.4810 - val_loss: 2.0048 - val_accuracy: 0.2639\n",
      "Epoch 128/200\n",
      "106/106 - 14s - loss: 1.3170 - accuracy: 0.4848 - val_loss: 1.7340 - val_accuracy: 0.3056\n",
      "Epoch 129/200\n",
      "106/106 - 14s - loss: 1.0916 - accuracy: 0.5626 - val_loss: 1.8502 - val_accuracy: 0.3194\n",
      "Epoch 130/200\n",
      "106/106 - 14s - loss: 1.1258 - accuracy: 0.5854 - val_loss: 1.9302 - val_accuracy: 0.2639\n",
      "Epoch 131/200\n",
      "106/106 - 14s - loss: 1.2631 - accuracy: 0.5474 - val_loss: 1.6887 - val_accuracy: 0.2917\n",
      "Epoch 132/200\n",
      "106/106 - 14s - loss: 1.1864 - accuracy: 0.5541 - val_loss: 1.7755 - val_accuracy: 0.3333\n",
      "Epoch 133/200\n",
      "106/106 - 14s - loss: 1.3085 - accuracy: 0.5247 - val_loss: 1.9608 - val_accuracy: 0.2222\n",
      "Epoch 134/200\n",
      "106/106 - 14s - loss: 1.5796 - accuracy: 0.4412 - val_loss: 2.0275 - val_accuracy: 0.2639\n",
      "Epoch 135/200\n",
      "106/106 - 14s - loss: 1.5545 - accuracy: 0.4393 - val_loss: 2.0158 - val_accuracy: 0.2361\n",
      "Epoch 136/200\n",
      "106/106 - 14s - loss: 1.4813 - accuracy: 0.4450 - val_loss: 2.0047 - val_accuracy: 0.2222\n",
      "Epoch 137/200\n",
      "106/106 - 14s - loss: 1.4534 - accuracy: 0.4763 - val_loss: 2.0557 - val_accuracy: 0.2083\n",
      "Epoch 138/200\n",
      "106/106 - 14s - loss: 1.5617 - accuracy: 0.4393 - val_loss: 1.9417 - val_accuracy: 0.2639\n",
      "Epoch 139/200\n",
      "106/106 - 14s - loss: 1.6147 - accuracy: 0.4013 - val_loss: 1.9556 - val_accuracy: 0.2083\n",
      "Epoch 140/200\n",
      "106/106 - 14s - loss: 1.5702 - accuracy: 0.4004 - val_loss: 1.9333 - val_accuracy: 0.2222\n",
      "Epoch 141/200\n",
      "106/106 - 14s - loss: 1.5542 - accuracy: 0.3880 - val_loss: 1.8353 - val_accuracy: 0.2778\n",
      "Epoch 142/200\n",
      "106/106 - 14s - loss: 1.5405 - accuracy: 0.4307 - val_loss: 1.8242 - val_accuracy: 0.2639\n",
      "Epoch 143/200\n",
      "106/106 - 14s - loss: 1.5371 - accuracy: 0.4383 - val_loss: 1.8733 - val_accuracy: 0.2500\n",
      "Epoch 144/200\n",
      "106/106 - 14s - loss: 1.5143 - accuracy: 0.4592 - val_loss: 1.9227 - val_accuracy: 0.2222\n",
      "Epoch 145/200\n",
      "106/106 - 14s - loss: 1.5376 - accuracy: 0.4269 - val_loss: 1.9673 - val_accuracy: 0.2639\n",
      "Epoch 146/200\n",
      "106/106 - 14s - loss: 1.5368 - accuracy: 0.4431 - val_loss: 1.9562 - val_accuracy: 0.2639\n",
      "Epoch 147/200\n",
      "106/106 - 14s - loss: 1.5464 - accuracy: 0.4364 - val_loss: 1.8600 - val_accuracy: 0.2500\n",
      "Epoch 148/200\n",
      "106/106 - 14s - loss: 1.4637 - accuracy: 0.4782 - val_loss: 1.8205 - val_accuracy: 0.2639\n",
      "Epoch 149/200\n",
      "106/106 - 14s - loss: 1.4488 - accuracy: 0.4839 - val_loss: 1.8034 - val_accuracy: 0.2500\n",
      "Epoch 150/200\n",
      "106/106 - 14s - loss: 1.5845 - accuracy: 0.4023 - val_loss: 1.8721 - val_accuracy: 0.2083\n",
      "Epoch 151/200\n",
      "106/106 - 14s - loss: 1.7649 - accuracy: 0.3197 - val_loss: 1.9755 - val_accuracy: 0.1806\n",
      "Epoch 152/200\n",
      "106/106 - 14s - loss: 1.7638 - accuracy: 0.2742 - val_loss: 2.0513 - val_accuracy: 0.0972\n",
      "Epoch 153/200\n",
      "106/106 - 14s - loss: 1.8117 - accuracy: 0.2495 - val_loss: 2.0397 - val_accuracy: 0.0972\n",
      "Epoch 154/200\n",
      "106/106 - 14s - loss: 1.8083 - accuracy: 0.2372 - val_loss: 2.0229 - val_accuracy: 0.0972\n",
      "Epoch 155/200\n",
      "106/106 - 14s - loss: 1.6524 - accuracy: 0.3510 - val_loss: 1.8717 - val_accuracy: 0.2083\n",
      "Epoch 156/200\n",
      "106/106 - 14s - loss: 1.5800 - accuracy: 0.3700 - val_loss: 1.8856 - val_accuracy: 0.2361\n",
      "Epoch 157/200\n",
      "106/106 - 14s - loss: 1.5669 - accuracy: 0.3672 - val_loss: 1.9154 - val_accuracy: 0.1944\n",
      "Epoch 158/200\n",
      "106/106 - 14s - loss: 1.5275 - accuracy: 0.3833 - val_loss: 1.9342 - val_accuracy: 0.2361\n",
      "Epoch 159/200\n",
      "106/106 - 14s - loss: 1.4840 - accuracy: 0.4089 - val_loss: 1.8767 - val_accuracy: 0.2361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "106/106 - 14s - loss: 1.4895 - accuracy: 0.4184 - val_loss: 1.8839 - val_accuracy: 0.2222\n",
      "Epoch 161/200\n",
      "106/106 - 14s - loss: 1.4974 - accuracy: 0.3928 - val_loss: 1.8339 - val_accuracy: 0.2639\n",
      "Epoch 162/200\n",
      "106/106 - 14s - loss: 1.4725 - accuracy: 0.4108 - val_loss: 1.8159 - val_accuracy: 0.2500\n",
      "Epoch 163/200\n",
      "106/106 - 14s - loss: 1.3710 - accuracy: 0.4469 - val_loss: 1.7917 - val_accuracy: 0.3194\n",
      "Epoch 164/200\n",
      "106/106 - 14s - loss: 1.3392 - accuracy: 0.4829 - val_loss: 1.7903 - val_accuracy: 0.2917\n",
      "Epoch 165/200\n",
      "106/106 - 14s - loss: 1.3535 - accuracy: 0.4687 - val_loss: 1.8711 - val_accuracy: 0.2778\n",
      "Epoch 166/200\n",
      "106/106 - 14s - loss: 1.4410 - accuracy: 0.4345 - val_loss: 1.8961 - val_accuracy: 0.2361\n",
      "Epoch 167/200\n",
      "106/106 - 14s - loss: 1.3855 - accuracy: 0.4402 - val_loss: 1.9206 - val_accuracy: 0.2361\n",
      "Epoch 168/200\n",
      "106/106 - 14s - loss: 1.3655 - accuracy: 0.4829 - val_loss: 1.7799 - val_accuracy: 0.2778\n",
      "Epoch 169/200\n",
      "106/106 - 14s - loss: 1.2914 - accuracy: 0.5066 - val_loss: 1.8402 - val_accuracy: 0.3056\n",
      "Epoch 170/200\n",
      "106/106 - 15s - loss: 1.2166 - accuracy: 0.5266 - val_loss: 1.7254 - val_accuracy: 0.3333\n",
      "Epoch 171/200\n",
      "106/106 - 14s - loss: 1.2071 - accuracy: 0.5389 - val_loss: 1.6876 - val_accuracy: 0.3750\n",
      "Epoch 172/200\n",
      "106/106 - 14s - loss: 1.1476 - accuracy: 0.5712 - val_loss: 1.6347 - val_accuracy: 0.3889\n",
      "Epoch 173/200\n",
      "106/106 - 14s - loss: 1.1545 - accuracy: 0.5626 - val_loss: 1.6819 - val_accuracy: 0.3333\n",
      "Epoch 174/200\n",
      "106/106 - 14s - loss: 1.1450 - accuracy: 0.5389 - val_loss: 1.7223 - val_accuracy: 0.3333\n",
      "Epoch 175/200\n",
      "106/106 - 14s - loss: 1.1331 - accuracy: 0.5560 - val_loss: 1.7912 - val_accuracy: 0.2917\n",
      "Epoch 176/200\n",
      "106/106 - 14s - loss: 1.1086 - accuracy: 0.5455 - val_loss: 1.7330 - val_accuracy: 0.3472\n",
      "Epoch 177/200\n",
      "106/106 - 14s - loss: 1.1446 - accuracy: 0.5332 - val_loss: 1.7722 - val_accuracy: 0.3194\n",
      "Epoch 178/200\n",
      "106/106 - 14s - loss: 1.1593 - accuracy: 0.5560 - val_loss: 1.7399 - val_accuracy: 0.3194\n",
      "Epoch 179/200\n",
      "106/106 - 14s - loss: 1.1126 - accuracy: 0.5617 - val_loss: 1.6767 - val_accuracy: 0.3472\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6b70592e1423>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     verbose=2)    \n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=200,\n",
    "    verbose=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

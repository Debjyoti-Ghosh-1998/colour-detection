{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from keras.layers import BatchNormalization, Lambda, Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category= FutureWarning)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mycolournet(num_classes):\n",
    "    input_image = Input(shape=(56,56,3))\n",
    "    layer1 = MaxPooling2D(pool_size=(1,1),strides=(1,1),input_shape=(56,56,3))(input_image)\n",
    "    \n",
    "    conv1 = Convolution2D(filters=32,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(layer1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(conv2)\n",
    "    \n",
    "    conv3 =  Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(conv3)\n",
    "    \n",
    "    concatoutput = Flatten()(conv2)\n",
    "    \n",
    "    commonFC_1 = Dense(units=20, activation='relu'  )(concatoutput)\n",
    "    commonFC_2 = Dense(units=50, activation = 'relu')(commonFC_1)\n",
    "    commonFC_3 = Dense(units=30, activation= 'relu')(commonFC_2)\n",
    "    output = Dense(units=num_classes,activation='softmax' )(commonFC_3)\n",
    "    \n",
    "    model = Model(inputs=input_image,outputs=output)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #sgd = SGD(lr=0.05, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mycolournet(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/colors/train'\n",
    "valid_path = 'data/colors/valid'\n",
    "test_path = 'data/colors/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 163 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['black','grey'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=[  'black','grey'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=[ 'black','grey' ], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 - 4s - loss: 0.4696 - accuracy: 0.8221\n",
      "Epoch 2/100\n",
      "17/17 - 1s - loss: 0.1263 - accuracy: 0.9693\n",
      "Epoch 3/100\n",
      "17/17 - 1s - loss: 0.0753 - accuracy: 0.9632\n",
      "Epoch 4/100\n",
      "17/17 - 1s - loss: 0.1547 - accuracy: 0.9448\n",
      "Epoch 5/100\n",
      "17/17 - 1s - loss: 0.0767 - accuracy: 0.9816\n",
      "Epoch 6/100\n",
      "17/17 - 1s - loss: 0.0265 - accuracy: 0.9939\n",
      "Epoch 7/100\n",
      "17/17 - 1s - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "17/17 - 1s - loss: 0.0211 - accuracy: 0.9877\n",
      "Epoch 9/100\n",
      "17/17 - 1s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "17/17 - 1s - loss: 0.0105 - accuracy: 0.9939\n",
      "Epoch 11/100\n",
      "17/17 - 1s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "17/17 - 2s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "17/17 - 1s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "17/17 - 1s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "17/17 - 1s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "17/17 - 2s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "17/17 - 2s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "17/17 - 1s - loss: 8.2772e-04 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "17/17 - 1s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "17/17 - 2s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "17/17 - 2s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "17/17 - 1s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "17/17 - 1s - loss: 7.3604e-04 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "17/17 - 1s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "17/17 - 2s - loss: 6.7970e-04 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "17/17 - 2s - loss: 6.1434e-04 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "17/17 - 1s - loss: 8.1561e-04 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "17/17 - 1s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "17/17 - 2s - loss: 9.4948e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "17/17 - 2s - loss: 7.3660e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "17/17 - 1s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "17/17 - 1s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "17/17 - 2s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-c45241690e3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     verbose=2)          \n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=100,\n",
    "    verbose=2)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mycolournet(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 590 images belonging to 4 classes.\n",
      "Found 12 images belonging to 4 classes.\n",
      "Found 2 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 - 30s - loss: 1.2102 - accuracy: 0.4017 - val_loss: 1.2395 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "59/59 - 28s - loss: 1.0035 - accuracy: 0.5102 - val_loss: 1.1750 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "59/59 - 30s - loss: 0.9887 - accuracy: 0.5576 - val_loss: 1.0463 - val_accuracy: 0.4167\n",
      "Epoch 4/20\n",
      "59/59 - 30s - loss: 0.9200 - accuracy: 0.6000 - val_loss: 0.9132 - val_accuracy: 0.9167\n",
      "Epoch 5/20\n",
      "59/59 - 29s - loss: 0.7953 - accuracy: 0.6729 - val_loss: 0.6043 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "59/59 - 29s - loss: 0.7210 - accuracy: 0.7017 - val_loss: 0.7984 - val_accuracy: 0.5833\n",
      "Epoch 7/20\n",
      "59/59 - 29s - loss: 0.7141 - accuracy: 0.7085 - val_loss: 0.4658 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "59/59 - 29s - loss: 0.6371 - accuracy: 0.7695 - val_loss: 0.5155 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "59/59 - 29s - loss: 0.6685 - accuracy: 0.7424 - val_loss: 0.5696 - val_accuracy: 0.9167\n",
      "Epoch 10/20\n",
      "59/59 - 29s - loss: 0.6739 - accuracy: 0.7271 - val_loss: 0.5291 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "59/59 - 29s - loss: 0.5914 - accuracy: 0.7814 - val_loss: 0.3382 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "59/59 - 29s - loss: 0.5673 - accuracy: 0.7983 - val_loss: 0.3358 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "59/59 - 29s - loss: 0.5448 - accuracy: 0.7847 - val_loss: 0.2790 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "59/59 - 29s - loss: 0.5123 - accuracy: 0.7949 - val_loss: 0.3944 - val_accuracy: 0.9167\n",
      "Epoch 15/20\n",
      "59/59 - 29s - loss: 0.4827 - accuracy: 0.8220 - val_loss: 0.2795 - val_accuracy: 0.9167\n",
      "Epoch 16/20\n",
      "59/59 - 29s - loss: 0.4339 - accuracy: 0.8424 - val_loss: 0.4966 - val_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "59/59 - 30s - loss: 0.4881 - accuracy: 0.8102 - val_loss: 0.3231 - val_accuracy: 0.9167\n",
      "Epoch 18/20\n",
      "59/59 - 29s - loss: 0.4431 - accuracy: 0.8458 - val_loss: 0.3083 - val_accuracy: 0.9167\n",
      "Epoch 19/20\n",
      "59/59 - 29s - loss: 0.4412 - accuracy: 0.8390 - val_loss: 0.4583 - val_accuracy: 0.8333\n",
      "Epoch 20/20\n",
      "59/59 - 31s - loss: 0.3938 - accuracy: 0.8508 - val_loss: 0.4255 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29497e94188>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=20,\n",
    "    verbose=2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mycolournet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 590 images belonging to 4 classes.\n",
      "Found 12 images belonging to 4 classes.\n",
      "Found 2 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 - 31s - loss: 1.2680 - accuracy: 0.3898 - val_loss: 1.3134 - val_accuracy: 0.4167\n",
      "Epoch 2/20\n",
      "59/59 - 29s - loss: 0.9520 - accuracy: 0.6153 - val_loss: 1.1495 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "59/59 - 29s - loss: 0.7269 - accuracy: 0.6780 - val_loss: 0.5975 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "59/59 - 30s - loss: 0.7055 - accuracy: 0.6542 - val_loss: 0.4983 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "59/59 - 31s - loss: 0.6654 - accuracy: 0.6915 - val_loss: 0.4917 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "59/59 - 31s - loss: 0.5701 - accuracy: 0.7508 - val_loss: 0.4008 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "59/59 - 29s - loss: 0.5662 - accuracy: 0.7458 - val_loss: 0.2479 - val_accuracy: 0.9167\n",
      "Epoch 8/20\n",
      "59/59 - 29s - loss: 0.5356 - accuracy: 0.7949 - val_loss: 0.2942 - val_accuracy: 0.9167\n",
      "Epoch 9/20\n",
      "59/59 - 30s - loss: 0.5558 - accuracy: 0.7831 - val_loss: 0.1450 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "59/59 - 29s - loss: 0.4721 - accuracy: 0.8203 - val_loss: 0.1634 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "59/59 - 30s - loss: 0.4823 - accuracy: 0.8153 - val_loss: 0.2101 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "59/59 - 30s - loss: 0.4337 - accuracy: 0.8339 - val_loss: 0.0954 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "59/59 - 29s - loss: 0.4223 - accuracy: 0.8390 - val_loss: 0.1405 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "59/59 - 29s - loss: 0.3988 - accuracy: 0.8356 - val_loss: 0.0921 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "59/59 - 29s - loss: 0.4052 - accuracy: 0.8441 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "59/59 - 30s - loss: 0.3840 - accuracy: 0.8576 - val_loss: 0.3279 - val_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "59/59 - 30s - loss: 0.3808 - accuracy: 0.8475 - val_loss: 0.2446 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "59/59 - 29s - loss: 0.3414 - accuracy: 0.8695 - val_loss: 0.1814 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "59/59 - 29s - loss: 0.3210 - accuracy: 0.8780 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "59/59 - 29s - loss: 0.3171 - accuracy: 0.8814 - val_loss: 0.0675 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29498b74108>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=20,\n",
    "    verbose=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mycolournet(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1282 images belonging to 9 classes.\n",
      "Found 83 images belonging to 9 classes.\n",
      "Found 2 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 - 82s - loss: 2.0879 - accuracy: 0.2340 - val_loss: 1.8139 - val_accuracy: 0.3373\n",
      "Epoch 2/50\n",
      "129/129 - 60s - loss: 1.7396 - accuracy: 0.3495 - val_loss: 1.5663 - val_accuracy: 0.3976\n",
      "Epoch 3/50\n",
      "129/129 - 60s - loss: 1.6766 - accuracy: 0.3619 - val_loss: 1.5967 - val_accuracy: 0.2892\n",
      "Epoch 4/50\n",
      "129/129 - 63s - loss: 1.5886 - accuracy: 0.3783 - val_loss: 1.4633 - val_accuracy: 0.3494\n",
      "Epoch 5/50\n",
      "129/129 - 63s - loss: 1.5561 - accuracy: 0.3768 - val_loss: 1.4249 - val_accuracy: 0.3133\n",
      "Epoch 6/50\n",
      "129/129 - 63s - loss: 1.4965 - accuracy: 0.4041 - val_loss: 1.4228 - val_accuracy: 0.3855\n",
      "Epoch 7/50\n",
      "129/129 - 63s - loss: 1.4747 - accuracy: 0.3861 - val_loss: 1.4991 - val_accuracy: 0.3253\n",
      "Epoch 8/50\n",
      "129/129 - 63s - loss: 1.3837 - accuracy: 0.4056 - val_loss: 1.4790 - val_accuracy: 0.3133\n",
      "Epoch 9/50\n",
      "129/129 - 63s - loss: 1.3806 - accuracy: 0.4337 - val_loss: 1.3952 - val_accuracy: 0.3253\n",
      "Epoch 10/50\n",
      "129/129 - 63s - loss: 1.3736 - accuracy: 0.4306 - val_loss: 1.3859 - val_accuracy: 0.3373\n",
      "Epoch 11/50\n",
      "129/129 - 64s - loss: 1.3540 - accuracy: 0.4376 - val_loss: 1.5103 - val_accuracy: 0.3253\n",
      "Epoch 12/50\n",
      "129/129 - 64s - loss: 1.3179 - accuracy: 0.4314 - val_loss: 1.3582 - val_accuracy: 0.3253\n",
      "Epoch 13/50\n",
      "129/129 - 63s - loss: 1.2684 - accuracy: 0.4579 - val_loss: 1.3074 - val_accuracy: 0.4096\n",
      "Epoch 14/50\n",
      "129/129 - 63s - loss: 1.2607 - accuracy: 0.4501 - val_loss: 1.3571 - val_accuracy: 0.3976\n",
      "Epoch 15/50\n",
      "129/129 - 63s - loss: 1.2070 - accuracy: 0.4821 - val_loss: 1.3455 - val_accuracy: 0.4337\n",
      "Epoch 16/50\n",
      "129/129 - 63s - loss: 1.2406 - accuracy: 0.4719 - val_loss: 1.2890 - val_accuracy: 0.4096\n",
      "Epoch 17/50\n",
      "129/129 - 66s - loss: 1.1877 - accuracy: 0.4789 - val_loss: 1.3823 - val_accuracy: 0.3133\n",
      "Epoch 18/50\n",
      "129/129 - 63s - loss: 1.1823 - accuracy: 0.4867 - val_loss: 1.3760 - val_accuracy: 0.3735\n",
      "Epoch 19/50\n",
      "129/129 - 63s - loss: 1.1631 - accuracy: 0.4977 - val_loss: 1.2551 - val_accuracy: 0.3373\n",
      "Epoch 20/50\n",
      "129/129 - 63s - loss: 1.1462 - accuracy: 0.4961 - val_loss: 1.2390 - val_accuracy: 0.4699\n",
      "Epoch 21/50\n",
      "129/129 - 63s - loss: 1.1215 - accuracy: 0.5374 - val_loss: 1.2890 - val_accuracy: 0.4819\n",
      "Epoch 22/50\n",
      "129/129 - 63s - loss: 1.1356 - accuracy: 0.5242 - val_loss: 1.1938 - val_accuracy: 0.5542\n",
      "Epoch 23/50\n",
      "129/129 - 66s - loss: 1.0891 - accuracy: 0.5476 - val_loss: 1.4169 - val_accuracy: 0.4578\n",
      "Epoch 24/50\n",
      "129/129 - 66s - loss: 1.0483 - accuracy: 0.5312 - val_loss: 1.2823 - val_accuracy: 0.4337\n",
      "Epoch 25/50\n",
      "129/129 - 63s - loss: 1.0579 - accuracy: 0.5429 - val_loss: 1.2574 - val_accuracy: 0.4699\n",
      "Epoch 26/50\n",
      "129/129 - 64s - loss: 1.0185 - accuracy: 0.5671 - val_loss: 1.4967 - val_accuracy: 0.4458\n",
      "Epoch 27/50\n",
      "129/129 - 63s - loss: 1.0029 - accuracy: 0.5796 - val_loss: 1.2235 - val_accuracy: 0.4217\n",
      "Epoch 28/50\n",
      "129/129 - 63s - loss: 0.9961 - accuracy: 0.5803 - val_loss: 1.2603 - val_accuracy: 0.5181\n",
      "Epoch 29/50\n",
      "129/129 - 63s - loss: 1.0290 - accuracy: 0.5491 - val_loss: 1.1462 - val_accuracy: 0.4819\n",
      "Epoch 30/50\n",
      "129/129 - 63s - loss: 1.0149 - accuracy: 0.5546 - val_loss: 1.2271 - val_accuracy: 0.4458\n",
      "Epoch 31/50\n",
      "129/129 - 63s - loss: 0.9369 - accuracy: 0.6030 - val_loss: 1.2380 - val_accuracy: 0.4940\n",
      "Epoch 32/50\n",
      "129/129 - 63s - loss: 0.9535 - accuracy: 0.5733 - val_loss: 1.2979 - val_accuracy: 0.4819\n",
      "Epoch 33/50\n",
      "129/129 - 63s - loss: 0.9617 - accuracy: 0.5967 - val_loss: 1.3185 - val_accuracy: 0.4578\n",
      "Epoch 34/50\n",
      "129/129 - 63s - loss: 0.9505 - accuracy: 0.6022 - val_loss: 1.2962 - val_accuracy: 0.4819\n",
      "Epoch 35/50\n",
      "129/129 - 64s - loss: 0.9348 - accuracy: 0.5881 - val_loss: 1.3005 - val_accuracy: 0.4578\n",
      "Epoch 36/50\n",
      "129/129 - 63s - loss: 0.8490 - accuracy: 0.6396 - val_loss: 1.2153 - val_accuracy: 0.4458\n",
      "Epoch 37/50\n",
      "129/129 - 63s - loss: 0.8732 - accuracy: 0.6357 - val_loss: 1.1544 - val_accuracy: 0.5181\n",
      "Epoch 38/50\n",
      "129/129 - 63s - loss: 0.8515 - accuracy: 0.6342 - val_loss: 1.1728 - val_accuracy: 0.5663\n",
      "Epoch 39/50\n",
      "129/129 - 64s - loss: 0.8280 - accuracy: 0.6482 - val_loss: 1.2583 - val_accuracy: 0.4940\n",
      "Epoch 40/50\n",
      "129/129 - 63s - loss: 0.8432 - accuracy: 0.6209 - val_loss: 1.1699 - val_accuracy: 0.5422\n",
      "Epoch 41/50\n",
      "129/129 - 63s - loss: 0.8344 - accuracy: 0.6427 - val_loss: 1.3126 - val_accuracy: 0.4699\n",
      "Epoch 42/50\n",
      "129/129 - 63s - loss: 0.8187 - accuracy: 0.6700 - val_loss: 1.2659 - val_accuracy: 0.5181\n",
      "Epoch 43/50\n",
      "129/129 - 69s - loss: 0.7584 - accuracy: 0.6856 - val_loss: 1.3290 - val_accuracy: 0.5060\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f8b0c050d8f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     verbose=2) \n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=50,\n",
    "    verbose=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mycolournet(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1098 images belonging to 9 classes.\n",
      "Found 83 images belonging to 9 classes.\n",
      "Found 2 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 - 54s - loss: 2.1859 - accuracy: 0.1512 - val_loss: 2.1224 - val_accuracy: 0.2169\n",
      "Epoch 2/50\n",
      "110/110 - 48s - loss: 2.0853 - accuracy: 0.2268 - val_loss: 1.9823 - val_accuracy: 0.2169\n",
      "Epoch 3/50\n",
      "110/110 - 48s - loss: 2.0163 - accuracy: 0.2295 - val_loss: 1.8917 - val_accuracy: 0.1807\n",
      "Epoch 4/50\n",
      "110/110 - 49s - loss: 1.8644 - accuracy: 0.2158 - val_loss: 1.7842 - val_accuracy: 0.2410\n",
      "Epoch 5/50\n",
      "110/110 - 48s - loss: 1.7579 - accuracy: 0.2851 - val_loss: 1.8275 - val_accuracy: 0.2892\n",
      "Epoch 6/50\n",
      "110/110 - 48s - loss: 1.7240 - accuracy: 0.3297 - val_loss: 1.7687 - val_accuracy: 0.2530\n",
      "Epoch 7/50\n",
      "110/110 - 48s - loss: 1.6994 - accuracy: 0.3424 - val_loss: 1.7461 - val_accuracy: 0.2892\n",
      "Epoch 8/50\n",
      "110/110 - 48s - loss: 1.6468 - accuracy: 0.3552 - val_loss: 1.7259 - val_accuracy: 0.2771\n",
      "Epoch 9/50\n",
      "110/110 - 49s - loss: 1.6331 - accuracy: 0.3770 - val_loss: 1.7260 - val_accuracy: 0.3253\n",
      "Epoch 10/50\n",
      "110/110 - 49s - loss: 1.6197 - accuracy: 0.3597 - val_loss: 1.7178 - val_accuracy: 0.3253\n",
      "Epoch 11/50\n",
      "110/110 - 49s - loss: 1.5865 - accuracy: 0.3734 - val_loss: 1.6768 - val_accuracy: 0.2771\n",
      "Epoch 12/50\n",
      "110/110 - 48s - loss: 1.5685 - accuracy: 0.3689 - val_loss: 1.6082 - val_accuracy: 0.2892\n",
      "Epoch 13/50\n",
      "110/110 - 48s - loss: 1.5263 - accuracy: 0.3907 - val_loss: 1.5328 - val_accuracy: 0.3735\n",
      "Epoch 14/50\n",
      "110/110 - 48s - loss: 1.4766 - accuracy: 0.3871 - val_loss: 1.4531 - val_accuracy: 0.4337\n",
      "Epoch 15/50\n",
      "110/110 - 48s - loss: 1.4790 - accuracy: 0.4035 - val_loss: 1.4871 - val_accuracy: 0.4217\n",
      "Epoch 16/50\n",
      "110/110 - 48s - loss: 1.4178 - accuracy: 0.4144 - val_loss: 1.4354 - val_accuracy: 0.3976\n",
      "Epoch 17/50\n",
      "110/110 - 49s - loss: 1.4209 - accuracy: 0.4399 - val_loss: 1.4239 - val_accuracy: 0.4337\n",
      "Epoch 18/50\n",
      "110/110 - 49s - loss: 1.3223 - accuracy: 0.4563 - val_loss: 1.4818 - val_accuracy: 0.4096\n",
      "Epoch 19/50\n",
      "110/110 - 48s - loss: 1.3315 - accuracy: 0.4617 - val_loss: 1.3822 - val_accuracy: 0.3735\n",
      "Epoch 20/50\n",
      "110/110 - 48s - loss: 1.3244 - accuracy: 0.4727 - val_loss: 1.3076 - val_accuracy: 0.4458\n",
      "Epoch 21/50\n",
      "110/110 - 48s - loss: 1.2746 - accuracy: 0.4872 - val_loss: 1.3929 - val_accuracy: 0.4217\n",
      "Epoch 22/50\n",
      "110/110 - 49s - loss: 1.2867 - accuracy: 0.4727 - val_loss: 1.3390 - val_accuracy: 0.4096\n",
      "Epoch 23/50\n",
      "110/110 - 48s - loss: 1.2677 - accuracy: 0.4718 - val_loss: 1.3581 - val_accuracy: 0.4458\n",
      "Epoch 24/50\n",
      "110/110 - 48s - loss: 1.2850 - accuracy: 0.4654 - val_loss: 1.4039 - val_accuracy: 0.4337\n",
      "Epoch 25/50\n",
      "110/110 - 48s - loss: 1.2474 - accuracy: 0.4854 - val_loss: 1.3306 - val_accuracy: 0.3976\n",
      "Epoch 26/50\n",
      "110/110 - 48s - loss: 1.2127 - accuracy: 0.4882 - val_loss: 1.2879 - val_accuracy: 0.4699\n",
      "Epoch 27/50\n",
      "110/110 - 49s - loss: 1.1833 - accuracy: 0.4882 - val_loss: 1.3370 - val_accuracy: 0.3976\n",
      "Epoch 28/50\n",
      "110/110 - 48s - loss: 1.1950 - accuracy: 0.5046 - val_loss: 1.3227 - val_accuracy: 0.3735\n",
      "Epoch 29/50\n",
      "110/110 - 49s - loss: 1.1759 - accuracy: 0.4954 - val_loss: 1.3187 - val_accuracy: 0.3976\n",
      "Epoch 30/50\n",
      "110/110 - 49s - loss: 1.1148 - accuracy: 0.5219 - val_loss: 1.4268 - val_accuracy: 0.4217\n",
      "Epoch 31/50\n",
      "110/110 - 48s - loss: 1.1122 - accuracy: 0.5091 - val_loss: 1.2929 - val_accuracy: 0.4096\n",
      "Epoch 32/50\n",
      "110/110 - 49s - loss: 1.1330 - accuracy: 0.5228 - val_loss: 1.2061 - val_accuracy: 0.3735\n",
      "Epoch 33/50\n",
      "110/110 - 48s - loss: 1.1089 - accuracy: 0.5137 - val_loss: 1.3606 - val_accuracy: 0.4699\n",
      "Epoch 34/50\n",
      "110/110 - 49s - loss: 1.1075 - accuracy: 0.5319 - val_loss: 1.3467 - val_accuracy: 0.3855\n",
      "Epoch 35/50\n",
      "110/110 - 49s - loss: 1.1164 - accuracy: 0.5200 - val_loss: 1.3451 - val_accuracy: 0.4578\n",
      "Epoch 36/50\n",
      "110/110 - 48s - loss: 1.0875 - accuracy: 0.5355 - val_loss: 1.3849 - val_accuracy: 0.4819\n",
      "Epoch 37/50\n",
      "110/110 - 48s - loss: 1.1112 - accuracy: 0.5301 - val_loss: 1.3467 - val_accuracy: 0.4940\n",
      "Epoch 38/50\n",
      "110/110 - 48s - loss: 1.0485 - accuracy: 0.5464 - val_loss: 1.2747 - val_accuracy: 0.4578\n",
      "Epoch 39/50\n",
      "110/110 - 48s - loss: 1.0524 - accuracy: 0.5583 - val_loss: 1.3226 - val_accuracy: 0.4940\n",
      "Epoch 40/50\n",
      "110/110 - 48s - loss: 1.0470 - accuracy: 0.5683 - val_loss: 1.3998 - val_accuracy: 0.3855\n",
      "Epoch 41/50\n",
      "110/110 - 48s - loss: 1.0416 - accuracy: 0.5492 - val_loss: 1.3818 - val_accuracy: 0.4337\n",
      "Epoch 42/50\n",
      "110/110 - 48s - loss: 0.9945 - accuracy: 0.5829 - val_loss: 1.3613 - val_accuracy: 0.4458\n",
      "Epoch 43/50\n",
      "110/110 - 48s - loss: 1.0232 - accuracy: 0.5719 - val_loss: 1.4538 - val_accuracy: 0.4458\n",
      "Epoch 44/50\n",
      "110/110 - 48s - loss: 0.9990 - accuracy: 0.5738 - val_loss: 1.3483 - val_accuracy: 0.4819\n",
      "Epoch 45/50\n",
      "110/110 - 48s - loss: 0.9722 - accuracy: 0.5920 - val_loss: 1.3919 - val_accuracy: 0.4337\n",
      "Epoch 46/50\n",
      "110/110 - 49s - loss: 1.0097 - accuracy: 0.5865 - val_loss: 1.3483 - val_accuracy: 0.5301\n",
      "Epoch 47/50\n",
      "110/110 - 48s - loss: 0.9666 - accuracy: 0.5893 - val_loss: 1.2929 - val_accuracy: 0.5181\n",
      "Epoch 48/50\n",
      "110/110 - 49s - loss: 0.9546 - accuracy: 0.6093 - val_loss: 1.3745 - val_accuracy: 0.4578\n",
      "Epoch 49/50\n",
      "110/110 - 48s - loss: 0.9150 - accuracy: 0.6120 - val_loss: 1.3225 - val_accuracy: 0.4699\n",
      "Epoch 50/50\n",
      "110/110 - 48s - loss: 0.9150 - accuracy: 0.6393 - val_loss: 1.3344 - val_accuracy: 0.4699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20b1c116148>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=50,\n",
    "    verbose=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mycolournet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1238 images belonging to 10 classes.\n",
      "Found 83 images belonging to 10 classes.\n",
      "Found 2 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink', 'white'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink', 'white'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink', 'white'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 - 62s - loss: 2.2517 - accuracy: 0.1858 - val_loss: 2.0363 - val_accuracy: 0.2651\n",
      "Epoch 2/100\n",
      "124/124 - 60s - loss: 2.0715 - accuracy: 0.2553 - val_loss: 2.0008 - val_accuracy: 0.2048\n",
      "Epoch 3/100\n",
      "124/124 - 61s - loss: 1.9976 - accuracy: 0.2851 - val_loss: 2.0046 - val_accuracy: 0.2289\n",
      "Epoch 4/100\n",
      "124/124 - 60s - loss: 1.9112 - accuracy: 0.3037 - val_loss: 1.9434 - val_accuracy: 0.2530\n",
      "Epoch 5/100\n",
      "124/124 - 61s - loss: 1.8622 - accuracy: 0.3288 - val_loss: 2.0301 - val_accuracy: 0.2289\n",
      "Epoch 6/100\n",
      "124/124 - 61s - loss: 1.8238 - accuracy: 0.3441 - val_loss: 1.9561 - val_accuracy: 0.2651\n",
      "Epoch 7/100\n",
      "124/124 - 61s - loss: 1.7706 - accuracy: 0.3813 - val_loss: 1.8268 - val_accuracy: 0.2651\n",
      "Epoch 8/100\n",
      "124/124 - 61s - loss: 1.6974 - accuracy: 0.3918 - val_loss: 2.0165 - val_accuracy: 0.2289\n",
      "Epoch 9/100\n",
      "124/124 - 61s - loss: 1.6588 - accuracy: 0.3998 - val_loss: 1.8378 - val_accuracy: 0.2410\n",
      "Epoch 10/100\n",
      "124/124 - 62s - loss: 1.6071 - accuracy: 0.4176 - val_loss: 1.7497 - val_accuracy: 0.2651\n",
      "Epoch 11/100\n",
      "124/124 - 60s - loss: 1.5500 - accuracy: 0.4273 - val_loss: 1.7249 - val_accuracy: 0.3012\n",
      "Epoch 12/100\n",
      "124/124 - 60s - loss: 1.5498 - accuracy: 0.4039 - val_loss: 1.6296 - val_accuracy: 0.2651\n",
      "Epoch 13/100\n",
      "124/124 - 61s - loss: 1.5064 - accuracy: 0.4063 - val_loss: 1.7259 - val_accuracy: 0.2892\n",
      "Epoch 14/100\n",
      "124/124 - 61s - loss: 1.4730 - accuracy: 0.4386 - val_loss: 1.5962 - val_accuracy: 0.3253\n",
      "Epoch 15/100\n",
      "124/124 - 61s - loss: 1.4495 - accuracy: 0.4523 - val_loss: 1.6427 - val_accuracy: 0.2892\n",
      "Epoch 16/100\n",
      "124/124 - 61s - loss: 1.3906 - accuracy: 0.4774 - val_loss: 1.5686 - val_accuracy: 0.3373\n",
      "Epoch 17/100\n",
      "124/124 - 61s - loss: 1.3858 - accuracy: 0.4709 - val_loss: 1.5401 - val_accuracy: 0.3855\n",
      "Epoch 18/100\n",
      "124/124 - 61s - loss: 1.3466 - accuracy: 0.4742 - val_loss: 1.5975 - val_accuracy: 0.3253\n",
      "Epoch 19/100\n",
      "124/124 - 61s - loss: 1.3518 - accuracy: 0.4758 - val_loss: 1.4665 - val_accuracy: 0.3133\n",
      "Epoch 20/100\n",
      "124/124 - 62s - loss: 1.3331 - accuracy: 0.4742 - val_loss: 1.5351 - val_accuracy: 0.3253\n",
      "Epoch 21/100\n",
      "124/124 - 61s - loss: 1.2844 - accuracy: 0.4976 - val_loss: 1.4725 - val_accuracy: 0.3976\n",
      "Epoch 22/100\n",
      "124/124 - 60s - loss: 1.2755 - accuracy: 0.4960 - val_loss: 1.3946 - val_accuracy: 0.3614\n",
      "Epoch 23/100\n",
      "124/124 - 61s - loss: 1.2254 - accuracy: 0.5178 - val_loss: 1.5548 - val_accuracy: 0.3253\n",
      "Epoch 24/100\n",
      "124/124 - 61s - loss: 1.1788 - accuracy: 0.5347 - val_loss: 1.5869 - val_accuracy: 0.2892\n",
      "Epoch 25/100\n",
      "124/124 - 61s - loss: 1.1715 - accuracy: 0.5323 - val_loss: 1.5358 - val_accuracy: 0.3494\n",
      "Epoch 26/100\n",
      "124/124 - 61s - loss: 1.1780 - accuracy: 0.5258 - val_loss: 1.4205 - val_accuracy: 0.3855\n",
      "Epoch 27/100\n",
      "124/124 - 61s - loss: 1.1845 - accuracy: 0.5145 - val_loss: 1.4761 - val_accuracy: 0.3012\n",
      "Epoch 28/100\n",
      "124/124 - 61s - loss: 1.1551 - accuracy: 0.5339 - val_loss: 1.5490 - val_accuracy: 0.3253\n",
      "Epoch 29/100\n",
      "124/124 - 61s - loss: 1.1560 - accuracy: 0.5428 - val_loss: 1.4296 - val_accuracy: 0.3855\n",
      "Epoch 30/100\n",
      "124/124 - 68s - loss: 1.1282 - accuracy: 0.5404 - val_loss: 1.4733 - val_accuracy: 0.4217\n",
      "Epoch 31/100\n",
      "124/124 - 89s - loss: 1.1002 - accuracy: 0.5670 - val_loss: 1.6421 - val_accuracy: 0.3133\n",
      "Epoch 32/100\n",
      "124/124 - 86s - loss: 1.1088 - accuracy: 0.5582 - val_loss: 1.3940 - val_accuracy: 0.4217\n",
      "Epoch 33/100\n",
      "124/124 - 83s - loss: 1.0385 - accuracy: 0.5784 - val_loss: 1.6193 - val_accuracy: 0.3012\n",
      "Epoch 34/100\n",
      "124/124 - 78s - loss: 1.0198 - accuracy: 0.5711 - val_loss: 1.5549 - val_accuracy: 0.3012\n",
      "Epoch 35/100\n",
      "124/124 - 75s - loss: 1.0402 - accuracy: 0.5897 - val_loss: 1.4836 - val_accuracy: 0.3373\n",
      "Epoch 36/100\n",
      "124/124 - 77s - loss: 1.0221 - accuracy: 0.5977 - val_loss: 1.3430 - val_accuracy: 0.3976\n",
      "Epoch 37/100\n",
      "124/124 - 79s - loss: 1.0013 - accuracy: 0.5969 - val_loss: 1.3671 - val_accuracy: 0.4096\n",
      "Epoch 38/100\n",
      "124/124 - 73s - loss: 0.9975 - accuracy: 0.6099 - val_loss: 1.5368 - val_accuracy: 0.3855\n",
      "Epoch 39/100\n",
      "124/124 - 71s - loss: 0.9589 - accuracy: 0.6252 - val_loss: 1.5854 - val_accuracy: 0.3494\n",
      "Epoch 40/100\n",
      "124/124 - 70s - loss: 0.9529 - accuracy: 0.6260 - val_loss: 1.5265 - val_accuracy: 0.3735\n",
      "Epoch 41/100\n",
      "124/124 - 77s - loss: 0.9627 - accuracy: 0.6179 - val_loss: 1.5702 - val_accuracy: 0.3373\n",
      "Epoch 42/100\n",
      "124/124 - 82s - loss: 0.9209 - accuracy: 0.6300 - val_loss: 1.4391 - val_accuracy: 0.4096\n",
      "Epoch 43/100\n",
      "124/124 - 76s - loss: 0.9048 - accuracy: 0.6438 - val_loss: 1.4733 - val_accuracy: 0.3614\n",
      "Epoch 44/100\n",
      "124/124 - 72s - loss: 0.8868 - accuracy: 0.6365 - val_loss: 1.6240 - val_accuracy: 0.4217\n",
      "Epoch 45/100\n",
      "124/124 - 69s - loss: 0.8933 - accuracy: 0.6365 - val_loss: 1.4899 - val_accuracy: 0.4096\n",
      "Epoch 46/100\n",
      "124/124 - 72s - loss: 0.8593 - accuracy: 0.6680 - val_loss: 1.6664 - val_accuracy: 0.3976\n",
      "Epoch 47/100\n",
      "124/124 - 71s - loss: 0.9172 - accuracy: 0.6389 - val_loss: 1.5299 - val_accuracy: 0.3614\n",
      "Epoch 48/100\n",
      "124/124 - 71s - loss: 0.9091 - accuracy: 0.6430 - val_loss: 1.4448 - val_accuracy: 0.4458\n",
      "Epoch 49/100\n",
      "124/124 - 67s - loss: 0.8132 - accuracy: 0.6834 - val_loss: 1.4655 - val_accuracy: 0.3735\n",
      "Epoch 50/100\n",
      "124/124 - 64s - loss: 0.8407 - accuracy: 0.6688 - val_loss: 1.4919 - val_accuracy: 0.4217\n",
      "Epoch 51/100\n",
      "124/124 - 62s - loss: 0.8286 - accuracy: 0.6729 - val_loss: 1.4534 - val_accuracy: 0.4458\n",
      "Epoch 52/100\n",
      "124/124 - 66s - loss: 0.8300 - accuracy: 0.6809 - val_loss: 1.5104 - val_accuracy: 0.4337\n",
      "Epoch 53/100\n",
      "124/124 - 62s - loss: 0.7830 - accuracy: 0.6866 - val_loss: 1.6556 - val_accuracy: 0.3855\n",
      "Epoch 54/100\n",
      "124/124 - 60s - loss: 0.7940 - accuracy: 0.6914 - val_loss: 1.4875 - val_accuracy: 0.4096\n",
      "Epoch 55/100\n",
      "124/124 - 61s - loss: 0.7621 - accuracy: 0.6939 - val_loss: 1.7235 - val_accuracy: 0.4217\n",
      "Epoch 56/100\n",
      "124/124 - 61s - loss: 0.7591 - accuracy: 0.6922 - val_loss: 1.8822 - val_accuracy: 0.3735\n",
      "Epoch 57/100\n",
      "124/124 - 62s - loss: 0.7697 - accuracy: 0.7003 - val_loss: 1.7199 - val_accuracy: 0.4096\n",
      "Epoch 58/100\n",
      "124/124 - 61s - loss: 0.7509 - accuracy: 0.6971 - val_loss: 1.6405 - val_accuracy: 0.4096\n",
      "Epoch 59/100\n",
      "124/124 - 61s - loss: 0.7241 - accuracy: 0.7189 - val_loss: 1.6902 - val_accuracy: 0.3373\n",
      "Epoch 60/100\n",
      "124/124 - 61s - loss: 0.7382 - accuracy: 0.7092 - val_loss: 1.4996 - val_accuracy: 0.4458\n",
      "Epoch 61/100\n",
      "124/124 - 61s - loss: 0.6791 - accuracy: 0.7286 - val_loss: 1.7063 - val_accuracy: 0.4217\n",
      "Epoch 62/100\n",
      "124/124 - 60s - loss: 0.7354 - accuracy: 0.7084 - val_loss: 1.8016 - val_accuracy: 0.3735\n",
      "Epoch 63/100\n",
      "124/124 - 61s - loss: 0.6914 - accuracy: 0.7326 - val_loss: 1.8079 - val_accuracy: 0.3735\n",
      "Epoch 64/100\n",
      "124/124 - 61s - loss: 0.6211 - accuracy: 0.7561 - val_loss: 1.7907 - val_accuracy: 0.4217\n",
      "Epoch 65/100\n",
      "124/124 - 61s - loss: 0.6818 - accuracy: 0.7536 - val_loss: 1.8181 - val_accuracy: 0.3976\n",
      "Epoch 66/100\n",
      "124/124 - 60s - loss: 0.6376 - accuracy: 0.7383 - val_loss: 1.8873 - val_accuracy: 0.3855\n",
      "Epoch 67/100\n",
      "124/124 - 61s - loss: 0.6646 - accuracy: 0.7439 - val_loss: 1.5733 - val_accuracy: 0.4578\n",
      "Epoch 68/100\n",
      "124/124 - 60s - loss: 0.6469 - accuracy: 0.7447 - val_loss: 1.6458 - val_accuracy: 0.4337\n",
      "Epoch 69/100\n",
      "124/124 - 60s - loss: 0.6500 - accuracy: 0.7415 - val_loss: 1.6710 - val_accuracy: 0.4699\n",
      "Epoch 70/100\n",
      "124/124 - 60s - loss: 0.6706 - accuracy: 0.7286 - val_loss: 1.7710 - val_accuracy: 0.3735\n",
      "Epoch 71/100\n",
      "124/124 - 60s - loss: 0.5900 - accuracy: 0.7698 - val_loss: 1.6112 - val_accuracy: 0.4578\n",
      "Epoch 72/100\n",
      "124/124 - 60s - loss: 0.5806 - accuracy: 0.7714 - val_loss: 1.7122 - val_accuracy: 0.4699\n",
      "Epoch 73/100\n",
      "124/124 - 60s - loss: 0.5580 - accuracy: 0.7892 - val_loss: 1.9565 - val_accuracy: 0.4217\n",
      "Epoch 74/100\n",
      "124/124 - 59s - loss: 0.5694 - accuracy: 0.7682 - val_loss: 1.7531 - val_accuracy: 0.4578\n",
      "Epoch 75/100\n",
      "124/124 - 60s - loss: 0.5722 - accuracy: 0.7868 - val_loss: 1.7392 - val_accuracy: 0.4217\n",
      "Epoch 76/100\n",
      "124/124 - 60s - loss: 0.5949 - accuracy: 0.7658 - val_loss: 1.7888 - val_accuracy: 0.4096\n",
      "Epoch 77/100\n",
      "124/124 - 60s - loss: 0.5677 - accuracy: 0.7722 - val_loss: 1.6887 - val_accuracy: 0.4217\n",
      "Epoch 78/100\n",
      "124/124 - 60s - loss: 0.5446 - accuracy: 0.7859 - val_loss: 1.7468 - val_accuracy: 0.4217\n",
      "Epoch 79/100\n",
      "124/124 - 60s - loss: 0.5225 - accuracy: 0.7924 - val_loss: 1.9072 - val_accuracy: 0.4337\n",
      "Epoch 80/100\n",
      "124/124 - 60s - loss: 0.5222 - accuracy: 0.7940 - val_loss: 1.7515 - val_accuracy: 0.4819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "124/124 - 61s - loss: 0.5525 - accuracy: 0.7738 - val_loss: 1.8961 - val_accuracy: 0.4337\n",
      "Epoch 82/100\n",
      "124/124 - 60s - loss: 0.5463 - accuracy: 0.7868 - val_loss: 1.7747 - val_accuracy: 0.4699\n",
      "Epoch 83/100\n",
      "124/124 - 8222s - loss: 0.5084 - accuracy: 0.7973 - val_loss: 1.9146 - val_accuracy: 0.4458\n",
      "Epoch 84/100\n",
      "124/124 - 67s - loss: 0.5262 - accuracy: 0.7940 - val_loss: 1.7539 - val_accuracy: 0.4458\n",
      "Epoch 85/100\n",
      "124/124 - 59s - loss: 0.5129 - accuracy: 0.7900 - val_loss: 1.7017 - val_accuracy: 0.4337\n",
      "Epoch 86/100\n",
      "124/124 - 32323s - loss: 0.5611 - accuracy: 0.7868 - val_loss: 2.0402 - val_accuracy: 0.4458\n",
      "Epoch 87/100\n",
      "124/124 - 60s - loss: 0.5236 - accuracy: 0.7908 - val_loss: 1.7533 - val_accuracy: 0.5181\n",
      "Epoch 88/100\n",
      "124/124 - 79s - loss: 0.5259 - accuracy: 0.7981 - val_loss: 1.9837 - val_accuracy: 0.4458\n",
      "Epoch 89/100\n",
      "124/124 - 62s - loss: 0.5044 - accuracy: 0.8069 - val_loss: 1.8154 - val_accuracy: 0.3735\n",
      "Epoch 90/100\n",
      "124/124 - 63s - loss: 0.4952 - accuracy: 0.8037 - val_loss: 1.7325 - val_accuracy: 0.4699\n",
      "Epoch 91/100\n",
      "124/124 - 65s - loss: 0.4593 - accuracy: 0.8142 - val_loss: 1.7740 - val_accuracy: 0.4940\n",
      "Epoch 92/100\n",
      "124/124 - 65s - loss: 0.4958 - accuracy: 0.8142 - val_loss: 2.0100 - val_accuracy: 0.4217\n",
      "Epoch 93/100\n",
      "124/124 - 63s - loss: 0.4999 - accuracy: 0.8102 - val_loss: 2.1847 - val_accuracy: 0.4337\n",
      "Epoch 94/100\n",
      "124/124 - 69s - loss: 0.4742 - accuracy: 0.8247 - val_loss: 2.2311 - val_accuracy: 0.4578\n",
      "Epoch 95/100\n",
      "124/124 - 70s - loss: 0.4999 - accuracy: 0.8053 - val_loss: 2.0491 - val_accuracy: 0.4940\n",
      "Epoch 96/100\n",
      "124/124 - 67s - loss: 0.4261 - accuracy: 0.8368 - val_loss: 1.9391 - val_accuracy: 0.4096\n",
      "Epoch 97/100\n",
      "124/124 - 65s - loss: 0.4423 - accuracy: 0.8207 - val_loss: 2.2471 - val_accuracy: 0.4699\n",
      "Epoch 98/100\n",
      "124/124 - 66s - loss: 0.4740 - accuracy: 0.8166 - val_loss: 2.1377 - val_accuracy: 0.3976\n",
      "Epoch 99/100\n",
      "124/124 - 65s - loss: 0.4403 - accuracy: 0.8457 - val_loss: 2.3673 - val_accuracy: 0.4699\n",
      "Epoch 100/100\n",
      "124/124 - 71s - loss: 0.4511 - accuracy: 0.8360 - val_loss: 1.9953 - val_accuracy: 0.4337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1846f615488>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=100,\n",
    "    verbose=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mycolournet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1422 images belonging to 10 classes.\n",
      "Found 83 images belonging to 10 classes.\n",
      "Found 2 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink', 'white'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink', 'white'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['blue', 'red', 'yellow', 'brown', 'green', 'grey','orange','purple','pink', 'white'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 - 85s - loss: 1.3925 - accuracy: 0.5260 - val_loss: 0.8760 - val_accuracy: 0.6988\n",
      "Epoch 2/150\n",
      "143/143 - 12s - loss: 0.6710 - accuracy: 0.7855 - val_loss: 0.8220 - val_accuracy: 0.7470\n",
      "Epoch 3/150\n",
      "143/143 - 12s - loss: 0.5803 - accuracy: 0.8129 - val_loss: 0.3855 - val_accuracy: 0.8675\n",
      "Epoch 4/150\n",
      "143/143 - 11s - loss: 0.4700 - accuracy: 0.8530 - val_loss: 0.3891 - val_accuracy: 0.8554\n",
      "Epoch 5/150\n",
      "143/143 - 12s - loss: 0.4073 - accuracy: 0.8734 - val_loss: 0.3037 - val_accuracy: 0.9277\n",
      "Epoch 6/150\n",
      "143/143 - 12s - loss: 0.3488 - accuracy: 0.8734 - val_loss: 0.2168 - val_accuracy: 0.9036\n",
      "Epoch 7/150\n",
      "143/143 - 12s - loss: 0.2688 - accuracy: 0.9142 - val_loss: 0.3395 - val_accuracy: 0.8916\n",
      "Epoch 8/150\n",
      "143/143 - 12s - loss: 0.2614 - accuracy: 0.9086 - val_loss: 0.2963 - val_accuracy: 0.9157\n",
      "Epoch 9/150\n",
      "143/143 - 12s - loss: 0.2082 - accuracy: 0.9381 - val_loss: 0.3895 - val_accuracy: 0.8916\n",
      "Epoch 10/150\n",
      "143/143 - 12s - loss: 0.2651 - accuracy: 0.9177 - val_loss: 0.3949 - val_accuracy: 0.8554\n",
      "Epoch 11/150\n",
      "143/143 - 12s - loss: 0.1793 - accuracy: 0.9381 - val_loss: 0.2518 - val_accuracy: 0.9277\n",
      "Epoch 12/150\n",
      "143/143 - 12s - loss: 0.1198 - accuracy: 0.9585 - val_loss: 0.3501 - val_accuracy: 0.9036\n",
      "Epoch 13/150\n",
      "143/143 - 12s - loss: 0.1242 - accuracy: 0.9613 - val_loss: 0.2585 - val_accuracy: 0.9398\n",
      "Epoch 14/150\n",
      "143/143 - 12s - loss: 0.0933 - accuracy: 0.9677 - val_loss: 0.6460 - val_accuracy: 0.8193\n",
      "Epoch 15/150\n",
      "143/143 - 12s - loss: 0.1082 - accuracy: 0.9655 - val_loss: 0.2784 - val_accuracy: 0.9157\n",
      "Epoch 16/150\n",
      "143/143 - 12s - loss: 0.1345 - accuracy: 0.9536 - val_loss: 0.5054 - val_accuracy: 0.8795\n",
      "Epoch 17/150\n",
      "143/143 - 12s - loss: 0.1489 - accuracy: 0.9515 - val_loss: 0.5928 - val_accuracy: 0.8554\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b97176398ac8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     verbose=2) \n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=150,\n",
    "    verbose=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/mycolourmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('models/mycolourmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4fcd30592f7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     verbose=2) \n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[0;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m         \"input: {}, {}\".format(\n\u001b[1;32m--> 964\u001b[1;33m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[0;32m    965\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "new_model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=10,\n",
    "    verbose=2)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/blackgreymodel.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=model.predict(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9990141e-01, 6.4550411e-05, 3.3962293e-05]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

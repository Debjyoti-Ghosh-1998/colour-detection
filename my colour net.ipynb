{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from keras.layers import BatchNormalization, Lambda, Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category= FutureWarning)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mycolournet(num_classes):\n",
    "    input_image = Input(shape=(56,56,3))\n",
    "    layer1 = MaxPooling2D(pool_size=(1,1),strides=(1,1),input_shape=(56,56,3))(input_image)\n",
    "    \n",
    "    blueinput =  Lambda(lambda x : x[:,:,:,0:1])(layer1)\n",
    "    greeninput =  Lambda(lambda x : x[:,:,:,1:2])(layer1)\n",
    "    redinput =  Lambda(lambda x : x[:,:,:,:2])(layer1)\n",
    "    \n",
    "    ##blueinput= torch.Tensor(blueinput)\n",
    "    ##redinput= torch.Tensor(redinput)\n",
    "    ##greeninput= torch.Tensor(greeninput)\n",
    "    \n",
    "    ##blueinput=blueinput.unsqueeze(dim=-1)\n",
    "    ##greeninput=greeninput.unsqueeze(dim=-1)\n",
    "    ##redinput= redinput.unsqueeze(dim=-1)\n",
    "    \n",
    "    ##blueinput=np.array(blueinput)\n",
    "    ##greeninput=np.array(greeninput)\n",
    "    ##redinput=np.array(redinput)\n",
    "    \n",
    "    blueconv1 = Convolution2D(filters=32,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(blueinput)\n",
    "    blueconv1 = BatchNormalization()(blueconv1)\n",
    "    blueconv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(blueconv1)\n",
    "    \n",
    "    greenconv1 = Convolution2D(filters=32,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(greeninput)\n",
    "    greenconv1 = BatchNormalization()(greenconv1)\n",
    "    greenconv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(greenconv1)\n",
    "    \n",
    "    redconv1 = Convolution2D(filters=32,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(redinput)\n",
    "    redconv1 = BatchNormalization()(redconv1)\n",
    "    redconv1 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(redconv1)\n",
    "    \n",
    "    blueconv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(blueconv1)\n",
    "    blueconv2 = BatchNormalization()(blueconv2)\n",
    "    blueconv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(blueconv2)\n",
    "    \n",
    "    greenconv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(greenconv1)\n",
    "    greenconv2 = BatchNormalization()(greenconv2)\n",
    "    greenconv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(greenconv2)\n",
    "    \n",
    "    redconv2 = Convolution2D(filters=64,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(redconv1)\n",
    "    redconv2 = BatchNormalization()(redconv2)\n",
    "    redconv2 = MaxPooling2D(pool_size=(3,3),strides=(2,2))(redconv2)\n",
    "    \n",
    "    blueflatten = Flatten()(blueconv2)\n",
    "    greenflatten = Flatten()(greenconv2)\n",
    "    redflatten = Flatten()(redconv2)\n",
    "    \n",
    "    blueFC_1 = Dense(units=1000, activation='relu')(blueflatten)\n",
    "    blueFC_1 = Dropout(0.6)(blueFC_1)\n",
    "    blueFC_2 = Dense(units=1, activation='relu')(blueFC_1)\n",
    "    \n",
    "    greenFC_1 = Dense(units=1000, activation='relu')(greenflatten)\n",
    "    greenFC_1 = Dropout(0.6)(greenFC_1)\n",
    "    greenFC_2 = Dense(units=1, activation='relu')(greenFC_1)\n",
    "    \n",
    "    redFC_1 = Dense(units=1000, activation='relu')(redflatten)\n",
    "    redFC_1 = Dropout(0.6)(redFC_1)\n",
    "    redFC_2 = Dense(units=1, activation='relu')(redFC_1)\n",
    "    \n",
    "    concatoutput = Concatenate()([blueFC_2, greenFC_2,redFC_2])\n",
    "    \n",
    "    commonFC_1 = Dense(units=20, activation='relu'  )(concatoutput)\n",
    "    commonFC_2 = Dense(units=50, activation = 'relu')(commonFC_1)\n",
    "    commonFC_3 = Dense(units=30, activation= 'relu')(commonFC_2)\n",
    "    output = Dense(units=num_classes,activation='softmax' )(commonFC_3)\n",
    "    \n",
    "    model = Model(inputs=input_image,outputs=output)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # sgd = SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mycolournet(3) #for two classes, i.e blue and red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=2871x299 at 0x22DF1663388>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visualkeras\n",
    "\n",
    "\n",
    "\n",
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='output.png') # write to disk\n",
    "visualkeras.layered_view(model, to_file='output.png').show() # write and show\n",
    "\n",
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 56, 56, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 56, 56, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 56, 56, 1)    0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 56, 56, 1)    0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 56, 56, 2)    0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 56, 56, 32)   320         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 56, 56, 32)   320         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 32)   608         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 56, 56, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 56, 56, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 27, 27, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 27, 27, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 27, 27, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 27, 27, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 27, 27, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 27, 27, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 27, 27, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 27, 27, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 27, 27, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 13, 13, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 13, 13, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10816)        0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10816)        0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 10816)        0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1000)         10817000    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1000)         10817000    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1000)         10817000    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1000)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1001        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1001        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            1001        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3)            0           dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 20)           80          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 50)           1050        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30)           1530        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 3)            93          dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 32,514,644\n",
      "Trainable params: 32,514,068\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data/colors')\n",
    "if os.path.isdir('train/blue') is False:\n",
    "    os.makedirs('train/blue')\n",
    "    os.makedirs('train/red')\n",
    "    os.makedirs('test/blue')\n",
    "    os.makedirs('test/red')\n",
    "    os.makedirs('valid/blue')\n",
    "    os.makedirs('valid/red')\n",
    "    \n",
    "os.chdir('../../')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/colors/train'\n",
    "valid_path = 'data/colors/valid'\n",
    "test_path = 'data/colors/test'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 646 images belonging to 4 classes.\n",
      "Found 41 images belonging to 4 classes.\n",
      "Found 0 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['orange', 'red', 'yellow', 'brown'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['orange', 'red','yellow', 'brown'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['orange', 'red','yellow','brown'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\PIL\\Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 - 23s - loss: 1.3530 - accuracy: 0.3638 - val_loss: 1.2797 - val_accuracy: 0.3902\n",
      "Epoch 2/100\n",
      "65/65 - 20s - loss: 1.0630 - accuracy: 0.5341 - val_loss: 0.9953 - val_accuracy: 0.5122\n",
      "Epoch 3/100\n",
      "65/65 - 20s - loss: 0.8827 - accuracy: 0.6161 - val_loss: 1.1650 - val_accuracy: 0.4390\n",
      "Epoch 4/100\n",
      "65/65 - 21s - loss: 0.7608 - accuracy: 0.6687 - val_loss: 0.7866 - val_accuracy: 0.6341\n",
      "Epoch 5/100\n",
      "65/65 - 20s - loss: 0.6211 - accuracy: 0.7585 - val_loss: 0.8630 - val_accuracy: 0.6098\n",
      "Epoch 6/100\n",
      "65/65 - 21s - loss: 0.5738 - accuracy: 0.7492 - val_loss: 0.7909 - val_accuracy: 0.7317\n",
      "Epoch 7/100\n",
      "65/65 - 21s - loss: 0.5693 - accuracy: 0.7693 - val_loss: 0.8725 - val_accuracy: 0.6098\n",
      "Epoch 8/100\n",
      "65/65 - 21s - loss: 0.5593 - accuracy: 0.7647 - val_loss: 0.6602 - val_accuracy: 0.7073\n",
      "Epoch 9/100\n",
      "65/65 - 21s - loss: 0.4637 - accuracy: 0.8080 - val_loss: 0.8490 - val_accuracy: 0.6829\n",
      "Epoch 10/100\n",
      "65/65 - 21s - loss: 0.4490 - accuracy: 0.8080 - val_loss: 0.9512 - val_accuracy: 0.6098\n",
      "Epoch 11/100\n",
      "65/65 - 20s - loss: 0.3414 - accuracy: 0.8762 - val_loss: 0.8683 - val_accuracy: 0.6829\n",
      "Epoch 12/100\n",
      "65/65 - 21s - loss: 0.4088 - accuracy: 0.8344 - val_loss: 1.1242 - val_accuracy: 0.6098\n",
      "Epoch 13/100\n",
      "65/65 - 21s - loss: 0.4005 - accuracy: 0.8560 - val_loss: 0.8627 - val_accuracy: 0.6829\n",
      "Epoch 14/100\n",
      "65/65 - 20s - loss: 0.3154 - accuracy: 0.8824 - val_loss: 0.6733 - val_accuracy: 0.7317\n",
      "Epoch 15/100\n",
      "65/65 - 20s - loss: 0.2831 - accuracy: 0.8916 - val_loss: 0.8447 - val_accuracy: 0.5610\n",
      "Epoch 16/100\n",
      "65/65 - 21s - loss: 0.3093 - accuracy: 0.8793 - val_loss: 1.3600 - val_accuracy: 0.5122\n",
      "Epoch 17/100\n",
      "65/65 - 20s - loss: 0.2322 - accuracy: 0.9180 - val_loss: 1.0694 - val_accuracy: 0.6341\n",
      "Epoch 18/100\n",
      "65/65 - 20s - loss: 0.2375 - accuracy: 0.8994 - val_loss: 1.0771 - val_accuracy: 0.6098\n",
      "Epoch 19/100\n",
      "65/65 - 20s - loss: 0.2627 - accuracy: 0.9025 - val_loss: 1.0219 - val_accuracy: 0.6585\n",
      "Epoch 20/100\n",
      "65/65 - 20s - loss: 0.3105 - accuracy: 0.8824 - val_loss: 0.9932 - val_accuracy: 0.6098\n",
      "Epoch 21/100\n",
      "65/65 - 20s - loss: 0.2265 - accuracy: 0.9241 - val_loss: 0.8639 - val_accuracy: 0.5610\n",
      "Epoch 22/100\n",
      "65/65 - 21s - loss: 0.2382 - accuracy: 0.9149 - val_loss: 1.2034 - val_accuracy: 0.6098\n",
      "Epoch 23/100\n",
      "65/65 - 20s - loss: 0.2119 - accuracy: 0.9241 - val_loss: 0.9373 - val_accuracy: 0.5854\n",
      "Epoch 24/100\n",
      "65/65 - 21s - loss: 0.1996 - accuracy: 0.9303 - val_loss: 0.9987 - val_accuracy: 0.7317\n",
      "Epoch 25/100\n",
      "65/65 - 20s - loss: 0.1931 - accuracy: 0.9257 - val_loss: 1.3520 - val_accuracy: 0.6341\n",
      "Epoch 26/100\n",
      "65/65 - 20s - loss: 0.1791 - accuracy: 0.9272 - val_loss: 1.7073 - val_accuracy: 0.5854\n",
      "Epoch 27/100\n",
      "65/65 - 21s - loss: 0.1456 - accuracy: 0.9381 - val_loss: 1.3864 - val_accuracy: 0.5854\n",
      "Epoch 28/100\n",
      "65/65 - 21s - loss: 0.1854 - accuracy: 0.9257 - val_loss: 1.5126 - val_accuracy: 0.6341\n",
      "Epoch 29/100\n",
      "65/65 - 21s - loss: 0.1995 - accuracy: 0.9272 - val_loss: 0.9682 - val_accuracy: 0.6585\n",
      "Epoch 30/100\n",
      "65/65 - 21s - loss: 0.1774 - accuracy: 0.9365 - val_loss: 1.0634 - val_accuracy: 0.6829\n",
      "Epoch 31/100\n",
      "65/65 - 20s - loss: 0.1082 - accuracy: 0.9706 - val_loss: 1.1306 - val_accuracy: 0.6098\n",
      "Epoch 32/100\n",
      "65/65 - 21s - loss: 0.1051 - accuracy: 0.9567 - val_loss: 1.2747 - val_accuracy: 0.6341\n",
      "Epoch 33/100\n",
      "65/65 - 21s - loss: 0.1336 - accuracy: 0.9551 - val_loss: 1.4918 - val_accuracy: 0.6098\n",
      "Epoch 34/100\n",
      "65/65 - 21s - loss: 0.1482 - accuracy: 0.9443 - val_loss: 1.1986 - val_accuracy: 0.6585\n",
      "Epoch 35/100\n",
      "65/65 - 23s - loss: 0.2142 - accuracy: 0.9180 - val_loss: 1.4399 - val_accuracy: 0.5854\n",
      "Epoch 36/100\n",
      "65/65 - 20s - loss: 0.1366 - accuracy: 0.9567 - val_loss: 0.8934 - val_accuracy: 0.6585\n",
      "Epoch 37/100\n",
      "65/65 - 20s - loss: 0.1206 - accuracy: 0.9567 - val_loss: 1.2926 - val_accuracy: 0.6585\n",
      "Epoch 38/100\n",
      "65/65 - 21s - loss: 0.0930 - accuracy: 0.9675 - val_loss: 1.0803 - val_accuracy: 0.6341\n",
      "Epoch 39/100\n",
      "65/65 - 20s - loss: 0.1187 - accuracy: 0.9505 - val_loss: 1.1083 - val_accuracy: 0.6585\n",
      "Epoch 40/100\n",
      "65/65 - 20s - loss: 0.0593 - accuracy: 0.9783 - val_loss: 1.3937 - val_accuracy: 0.6829\n",
      "Epoch 41/100\n",
      "65/65 - 21s - loss: 0.0959 - accuracy: 0.9628 - val_loss: 1.3955 - val_accuracy: 0.5854\n",
      "Epoch 42/100\n",
      "65/65 - 21s - loss: 0.0596 - accuracy: 0.9768 - val_loss: 1.3340 - val_accuracy: 0.6098\n",
      "Epoch 43/100\n",
      "65/65 - 21s - loss: 0.0735 - accuracy: 0.9830 - val_loss: 1.7634 - val_accuracy: 0.5122\n",
      "Epoch 44/100\n",
      "65/65 - 21s - loss: 0.1013 - accuracy: 0.9628 - val_loss: 1.5115 - val_accuracy: 0.6341\n",
      "Epoch 45/100\n",
      "65/65 - 21s - loss: 0.1017 - accuracy: 0.9752 - val_loss: 1.1125 - val_accuracy: 0.6585\n",
      "Epoch 46/100\n",
      "65/65 - 20s - loss: 0.0955 - accuracy: 0.9644 - val_loss: 1.3229 - val_accuracy: 0.5366\n",
      "Epoch 47/100\n",
      "65/65 - 20s - loss: 0.0617 - accuracy: 0.9814 - val_loss: 1.3636 - val_accuracy: 0.6829\n",
      "Epoch 48/100\n",
      "65/65 - 20s - loss: 0.0809 - accuracy: 0.9690 - val_loss: 1.2778 - val_accuracy: 0.6829\n",
      "Epoch 49/100\n",
      "65/65 - 20s - loss: 0.0717 - accuracy: 0.9783 - val_loss: 1.5444 - val_accuracy: 0.6341\n",
      "Epoch 50/100\n",
      "65/65 - 20s - loss: 0.0592 - accuracy: 0.9799 - val_loss: 1.4347 - val_accuracy: 0.6098\n",
      "Epoch 51/100\n",
      "65/65 - 21s - loss: 0.0991 - accuracy: 0.9659 - val_loss: 1.2211 - val_accuracy: 0.6585\n",
      "Epoch 52/100\n",
      "65/65 - 21s - loss: 0.0756 - accuracy: 0.9690 - val_loss: 1.6486 - val_accuracy: 0.6341\n",
      "Epoch 53/100\n",
      "65/65 - 23s - loss: 0.0447 - accuracy: 0.9845 - val_loss: 1.6499 - val_accuracy: 0.6098\n",
      "Epoch 54/100\n",
      "65/65 - 21s - loss: 0.1257 - accuracy: 0.9536 - val_loss: 1.9870 - val_accuracy: 0.5610\n",
      "Epoch 55/100\n",
      "65/65 - 20s - loss: 0.0753 - accuracy: 0.9783 - val_loss: 1.6577 - val_accuracy: 0.6098\n",
      "Epoch 56/100\n",
      "65/65 - 21s - loss: 0.0743 - accuracy: 0.9768 - val_loss: 1.0555 - val_accuracy: 0.6341\n",
      "Epoch 57/100\n",
      "65/65 - 20s - loss: 0.0633 - accuracy: 0.9721 - val_loss: 1.1797 - val_accuracy: 0.6341\n",
      "Epoch 58/100\n",
      "65/65 - 20s - loss: 0.0430 - accuracy: 0.9861 - val_loss: 1.4067 - val_accuracy: 0.7073\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2cf6eb17a08f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=100,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 236 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=[ 'orange', 'yellow'], batch_size=10,class_mode='categorical')\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=[ 'orange', 'yellow'], batch_size=10,class_mode='categorical')\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=[ 'orange','yellow'], batch_size=10,class_mode='categorical', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 - 9s - loss: 0.6284 - accuracy: 0.6653\n",
      "Epoch 2/10\n",
      "24/24 - 7s - loss: 0.4049 - accuracy: 0.8390\n",
      "Epoch 3/10\n",
      "24/24 - 7s - loss: 0.2823 - accuracy: 0.8941\n",
      "Epoch 4/10\n",
      "24/24 - 7s - loss: 0.2326 - accuracy: 0.9153\n",
      "Epoch 5/10\n",
      "24/24 - 7s - loss: 0.1507 - accuracy: 0.9534\n",
      "Epoch 6/10\n",
      "24/24 - 7s - loss: 0.1102 - accuracy: 0.9576\n",
      "Epoch 7/10\n",
      "24/24 - 7s - loss: 0.0877 - accuracy: 0.9703\n",
      "Epoch 8/10\n",
      "24/24 - 8s - loss: 0.0759 - accuracy: 0.9746\n",
      "Epoch 9/10\n",
      "24/24 - 9s - loss: 0.0678 - accuracy: 0.9746\n",
      "Epoch 10/10\n",
      "24/24 - 7s - loss: 0.0186 - accuracy: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2030ce0ef08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=10,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 454 images belonging to 3 classes.\n",
      "Found 30 images belonging to 3 classes.\n",
      "Found 2 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['blue', 'green', 'purple'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['blue', 'green', 'purple'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['blue', 'green', 'purple'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 - 16s - loss: 1.0062 - accuracy: 0.5308 - val_loss: 0.7146 - val_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "46/46 - 14s - loss: 0.5223 - accuracy: 0.7577 - val_loss: 0.5631 - val_accuracy: 0.5667\n",
      "Epoch 3/100\n",
      "46/46 - 14s - loss: 0.4963 - accuracy: 0.7907 - val_loss: 0.6350 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "46/46 - 14s - loss: 0.4405 - accuracy: 0.8062 - val_loss: 0.4741 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "46/46 - 14s - loss: 0.4242 - accuracy: 0.7885 - val_loss: 0.5199 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "46/46 - 14s - loss: 0.4026 - accuracy: 0.8106 - val_loss: 0.7846 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "46/46 - 14s - loss: 0.3720 - accuracy: 0.8260 - val_loss: 0.5672 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "46/46 - 14s - loss: 0.3514 - accuracy: 0.8150 - val_loss: 0.6240 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "46/46 - 14s - loss: 0.3191 - accuracy: 0.8348 - val_loss: 0.7646 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "46/46 - 14s - loss: 0.2961 - accuracy: 0.8458 - val_loss: 0.9806 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "46/46 - 14s - loss: 0.2693 - accuracy: 0.8612 - val_loss: 0.9964 - val_accuracy: 0.6333\n",
      "Epoch 12/100\n",
      "46/46 - 14s - loss: 0.2582 - accuracy: 0.8700 - val_loss: 0.6965 - val_accuracy: 0.6333\n",
      "Epoch 13/100\n",
      "46/46 - 15s - loss: 0.2423 - accuracy: 0.9097 - val_loss: 0.8588 - val_accuracy: 0.6333\n",
      "Epoch 14/100\n",
      "46/46 - 16s - loss: 0.2381 - accuracy: 0.8899 - val_loss: 0.6149 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "46/46 - 15s - loss: 0.2202 - accuracy: 0.9251 - val_loss: 0.6566 - val_accuracy: 0.7000\n",
      "Epoch 16/100\n",
      "46/46 - 14s - loss: 0.1335 - accuracy: 0.9493 - val_loss: 0.6338 - val_accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "46/46 - 15s - loss: 0.1336 - accuracy: 0.9559 - val_loss: 0.8335 - val_accuracy: 0.6333\n",
      "Epoch 18/100\n",
      "46/46 - 16s - loss: 0.1051 - accuracy: 0.9581 - val_loss: 1.0537 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "46/46 - 15s - loss: 0.1641 - accuracy: 0.9427 - val_loss: 1.3099 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "46/46 - 16s - loss: 0.0871 - accuracy: 0.9780 - val_loss: 0.9452 - val_accuracy: 0.7000\n",
      "Epoch 21/100\n",
      "46/46 - 16s - loss: 0.0862 - accuracy: 0.9648 - val_loss: 1.4117 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "46/46 - 17s - loss: 0.0969 - accuracy: 0.9648 - val_loss: 1.2005 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "46/46 - 17s - loss: 0.0490 - accuracy: 0.9846 - val_loss: 1.0598 - val_accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "46/46 - 16s - loss: 0.0456 - accuracy: 0.9802 - val_loss: 1.6793 - val_accuracy: 0.7000\n",
      "Epoch 25/100\n",
      "46/46 - 17s - loss: 0.0613 - accuracy: 0.9846 - val_loss: 1.0992 - val_accuracy: 0.7333\n",
      "Epoch 26/100\n",
      "46/46 - 15s - loss: 0.0312 - accuracy: 0.9868 - val_loss: 1.2951 - val_accuracy: 0.6667\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2cf6eb17a08f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\Debjyoty\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=100,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 366 images belonging to 2 classes.\n",
      "Found 12 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(56,56), classes=['blue', 'red'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(56,56), classes=['blue', 'red'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(56,56), classes=['blue', 'red'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 - 5s - loss: 0.6933 - accuracy: 0.4815 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "17/17 - 5s - loss: 0.6933 - accuracy: 0.4691 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "17/17 - 5s - loss: 0.6933 - accuracy: 0.5185 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "17/17 - 5s - loss: 0.6934 - accuracy: 0.4259 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "17/17 - 5s - loss: 0.6934 - accuracy: 0.4815 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "17/17 - 5s - loss: 0.6933 - accuracy: 0.4815 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "17/17 - 5s - loss: 0.6932 - accuracy: 0.5185 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "17/17 - 5s - loss: 0.6931 - accuracy: 0.5185 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "17/17 - 6s - loss: 0.6931 - accuracy: 0.5185 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "17/17 - 6s - loss: 0.6929 - accuracy: 0.5185 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "17/17 - 6s - loss: 0.6928 - accuracy: 0.5185 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "17/17 - 6s - loss: 0.6928 - accuracy: 0.5185 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "17/17 - 6s - loss: 0.6926 - accuracy: 0.5185 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "17/17 - 6s - loss: 0.6928 - accuracy: 0.5185 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "17/17 - 6s - loss: 0.6926 - accuracy: 0.5185 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "17/17 - 6s - loss: 0.6925 - accuracy: 0.5185 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "17/17 - 6s - loss: 0.6925 - accuracy: 0.5185 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "17/17 - 6s - loss: 0.6925 - accuracy: 0.5185 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 19/20\n",
      "17/17 - 6s - loss: 0.6929 - accuracy: 0.5185 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 20/20\n",
      "17/17 - 6s - loss: 0.6926 - accuracy: 0.5185 - val_loss: 0.6937 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fd84064f08>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "    steps_per_epoch=len(train_batches),\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=20,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s\n"
     ]
    }
   ],
   "source": [
    "item,label = next(test_batches)\n",
    "pred= model.predict(x= test_batches, steps = len(test_batches), verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.999914e-01, 8.615208e-06]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predclass= np.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"blueimg1.jpg\"\n",
    "img= cv.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.resize(img, (56,56))\n",
    "imgarray= image.img_to_array(img)\n",
    "imgbatch= np.expand_dims(imgarray,axis=0)\n",
    "imgpreprocess=tf.keras.applications.vgg16.preprocess_input(imgbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-602ad7a9f96b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgpreprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pred= model.predict(imgpreprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38193777, 0.15231289, 0.46574935]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-347b7d0ec1dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/my_model_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_weights('models/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/firstmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
